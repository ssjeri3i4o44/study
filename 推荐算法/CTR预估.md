# CTR预估

点击率(Click through rate)是点击特定链接的用户与查看页面，电子邮件或广告的总用户数量之比。 它通常用于衡量某个网站的在线广告活动是否成功，以及电子邮件活动的有效性。 
$$
CTR = （广告点击次数/广告投放次数）*100%
$$


## 1.数据探索

基础特征筛选：场景、广告、媒体、用户

单特征选择的方法：

- 简单统计法：LDA,PCA

- 特征选择指标
  - 去冗余：特征直接相关性（皮尔逊相关性）
  - 去无用：信息增益比

## 2.常见算法

### 2.1 LR

线性模型，各特征独立考虑，没有考虑特征之间的相关性

### 2.2  GBDT+LR

使用GBDT的非线性进行组合特征的学习，LR来学习特征的关联最终预测出点击率。

将一些连续值特征、值空间不大的类别特征都丢给GBDT模型，把GBDT训练得到的每颗树的叶节点编号作为新的特征加入到原始特征集中，再用LR模型训练最终的模型。

### 2.3FM模型（因式分解机）

广告业务中会有很多类别特征，做完one-hot之后会变得特别稀疏，特征空间会变得特别大。FM就是为了解决特征组合下数据稀疏所带来的一些列问题。

FM：考虑了特征直接的相关性，采用多项式模型，解决数据稀疏情况下，特征怎样组合的问题

FM算法优点：

- 可以在非常稀疏的数据中进行合理参数估计
- FM模型的时间复杂是线性的
- FM是通用模型，可以用于任何特征为实值

### 2.4 FFM模型（Field-aware Factorization Machine)

FFM把相同性质的特征归于同一个field。同一个类别特征经过one-hot编码生成的数值特征都可以放在同一个field中。假设样本的n个特征属于f个field，那么FFM的二次项有nf个隐向量。

训练FFM过程中细节：

- 样本归一化
- 特征归一化（源数值型特征归一化）
- 省略零值特征



## 总结

- [ ] FM比LR引进了特征组合（二次项）

- [ ] FM解决了数据稀疏性导致的参数训练不重复问题（特别是one-hot编码后）

- [ ] FFM增加了field，隐向量不仅和特征相关，也和field相关

- [ ] 假设样本的n个特征属于f个field，那么FFM的二次项有nf个隐向量，而FM中只有一个向量。

- [ ] FM可以看做是FFM的特例，是把所有的特征都归属到一个field时的FFM

  

协同过滤、关联算法、LTR、BPR，SVD,特征选择算法、query分析、召回算法、排序算法

# SVD（奇异值分解）：

- 优点：简化数据，去除噪声点，提高算法的结果；

- 缺点：数据的转换可能难以理解；

- 适用于数据类型：数值型

SVD又称奇异值分解，是线性代数中一种矩阵分解的技术，它能够将任意一个m\*n的矩阵A分解成为U、S、V，U是m\*m的正交矩阵，V是n\**n的正交矩阵，S是m*\*n的矩阵，且A=U*S*V。通过SVD方式将矩阵A分解后，如果只保留前k个最大的奇异值，就实现了对矩阵降维的目的。

缺点：需要不全稀疏矩阵；计算复杂度较高。

Funk-SVD：将原始的评分矩阵A分解为P、Q，同时考虑原始评分矩阵中有评分的项分解是否准确（均方差最小）,如果不是，用梯度下降优化。

