{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T06:27:03.606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             样本id   A1     A2     A3   A4        A5    A6   A7  A8        A9  \\\n",
      "120    sample_842  300  125.0    NaN  980  14:30:00  24.0  NaN NaN  16:00:00   \n",
      "138   sample_1001  300    NaN  405.0  700   1:00:00  21.0  NaN NaN   2:30:00   \n",
      "248   sample_1040  200    NaN  270.0  470   9:30:00  21.0  NaN NaN  11:00:00   \n",
      "322    sample_996  300    NaN  405.0  700   4:00:00  30.0  NaN NaN   5:00:00   \n",
      "447    sample_994  300    NaN  405.0  700  10:40:00  28.0  NaN NaN  11:50:00   \n",
      "484    sample_752  300    NaN  405.0  700  20:00:00  28.0  NaN NaN  22:00:00   \n",
      "687    sample_748  300    NaN  405.0  700  15:00:00  30.0  NaN NaN  17:00:00   \n",
      "762    sample_849  300  125.0    NaN  980   5:30:00  21.0  NaN NaN   7:00:00   \n",
      "869    sample_293  300  125.0    NaN  980  15:00:00  21.0  NaN NaN  16:00:00   \n",
      "956    sample_450  300    NaN  405.0  700  23:00:00  21.0  NaN NaN   0:30:00   \n",
      "1012   sample_751  300    NaN  405.0  700   8:30:00  28.0  NaN NaN  10:30:00   \n",
      "1195   sample_750  300    NaN  405.0  700   2:00:00  28.0  NaN NaN   4:00:00   \n",
      "1201   sample_451  300    NaN  405.0  700   8:00:00  22.0  NaN NaN   9:00:00   \n",
      "\n",
      "      ...    B6        B7    B8           B9          B10  B11     B12   B13  \\\n",
      "120   ...    60   6:00:00  40.0   9:00-10:30  11:30-13:00  NaN   800.0  0.15   \n",
      "138   ...    60  19:00:00  36.0  19:30-21:00  21:40-23:10  NaN   800.0  0.15   \n",
      "248   ...    65  20:00:00  45.0  20:00-21:30          NaN  NaN   400.0  0.15   \n",
      "322   ...    65  17:00:00  45.0    0:00-1:30    2:00-3:30  NaN   800.0  0.15   \n",
      "447   ...    55  22:30:00  40.0   23:30-1:00    1:30-2:30  NaN   800.0  0.15   \n",
      "484   ...    80  11:00:00  45.0   11:00-4:00          NaN  NaN  1200.0  0.15   \n",
      "687   ...    80   2:00:00  45.0   2:00-17:00          NaN  NaN  1200.0  0.15   \n",
      "762   ...    65  23:00:00  40.0    1:00-2:30    4:30-7:00  NaN   800.0  0.15   \n",
      "869   ...    60   7:30:00  40.0  12:30-14:00  14:30-16:00  NaN   800.0  0.15   \n",
      "956   ...    65  11:30:00  40.0  13:30-15:00  15:30-17:00  NaN   800.0  0.15   \n",
      "1012  ...    80  23:00:00  45.0   23:00-7:30          NaN  NaN  1200.0  0.15   \n",
      "1195  ...    80  13:00:00  45.0  13:00-14:30          NaN  NaN  1200.0  0.15   \n",
      "1201  ...    65  19:00:00  35.0    0:00-1:30    2:30-4:00  NaN   800.0   NaN   \n",
      "\n",
      "      B14     收率  \n",
      "120   280  0.624  \n",
      "138   380  0.868  \n",
      "248   256  0.866  \n",
      "322   400  0.868  \n",
      "447   280  0.857  \n",
      "484   380  0.803  \n",
      "687   400  0.846  \n",
      "762   370  0.834  \n",
      "869   400  0.677  \n",
      "956   380  0.868  \n",
      "1012  400  0.868  \n",
      "1195  380  0.834  \n",
      "1201  380  0.868  \n",
      "\n",
      "[13 rows x 44 columns]\n",
      "280\n",
      "44    sample_1043\n",
      "Name: 样本id, dtype: object\n",
      "Int64Index([44], dtype='int64')\n",
      "Int64Index([44], dtype='int64')\n",
      "385\n",
      "1    sample_1548\n",
      "Name: 样本id, dtype: object\n",
      "Int64Index([1], dtype='int64')\n",
      "Int64Index([1], dtype='int64')\n",
      "390\n",
      "29     sample_309\n",
      "50    sample_1522\n",
      "Name: 样本id, dtype: object\n",
      "Int64Index([29, 50], dtype='int64')\n",
      "Int64Index([29, 50], dtype='int64')\n",
      "785\n",
      "37    sample_316\n",
      "Name: 样本id, dtype: object\n",
      "Int64Index([37], dtype='int64')\n",
      "Int64Index([37], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:120: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:133: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  0%|▏                                                                                | 3/1329 [00:00<01:00, 21.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 8, 9, 11, 12, 13, 14, 16, 17, 21, 22, 24, 25, 26, 27, 29, 30, 33, 34, 36, 37, 39, 41, 42, 43, 44, 45, 47, 50, 51, 52, 57, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 82, 84, 85, 87, 88, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 113, 115, 116, 117, 118, 120, 121, 122, 124, 126, 127, 128, 129, 130, 131, 132, 133, 135, 137, 138, 139, 140, 141, 144, 147, 148, 150, 151, 152, 154, 156, 158, 159, 161, 163, 164, 165, 166, 167, 168, 169, 170, 173, 174, 175, 177, 179, 180, 181, 182, 184, 186, 187, 189, 190, 194, 195, 196, 198, 200, 202, 204, 206, 208, 209, 210, 212, 213, 214, 217, 219, 222, 223, 225, 226, 227, 229, 231, 232, 233, 235, 236, 237, 238, 239, 240, 242, 243, 244, 245, 246, 247, 248, 249, 251, 253, 256, 257, 258, 259, 262, 264, 266, 267, 268, 270, 273, 274, 275, 276, 278, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292, 294, 296, 297, 298, 301, 305, 306, 307, 308, 313, 314, 315, 317, 321, 322, 324, 325, 326, 328, 329, 330, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 347, 349, 350, 351, 353, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 378, 381, 383, 384, 388, 389, 390, 392, 393, 395, 396, 397, 398, 399, 401, 402, 404, 405, 407, 408, 410, 411, 412, 414, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 427, 429, 430, 431, 432, 433, 434, 436, 438, 440, 442, 445, 448, 449, 455, 456, 457, 461, 463, 464, 465, 467, 469, 470, 471, 472, 473, 475, 477, 478, 481, 483, 484, 485, 487, 489, 491, 493, 494, 495, 496, 497, 498, 499, 500, 501, 503, 505, 506, 508, 509, 510, 511, 514, 515, 516, 521, 524, 525, 526, 528, 529, 532, 534, 535, 536, 538, 541, 542, 543, 544, 545, 546, 548, 549, 550, 551, 552, 553, 555, 556, 557, 560, 561, 562, 563, 567, 568, 570, 571, 572, 574, 577, 578, 581, 582, 584, 585, 586, 587, 589, 590, 591, 592, 593, 594, 595, 596, 599, 600, 601, 602, 604, 605, 606, 607, 608, 609, 612, 613, 614, 615, 617, 618, 621, 623, 624, 625, 626, 627, 628, 629, 631, 632, 634, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 650, 651, 653, 654, 657, 658, 660, 661, 662, 663, 664, 665, 669, 670, 671, 672, 673, 674, 676, 679, 680, 681, 682, 684, 685, 686, 691, 692, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 710, 711, 715, 716, 717, 719, 720, 721, 723, 725, 726, 728, 729, 730, 731, 732, 733, 735, 736, 737, 738, 739, 740, 742, 743, 753, 754, 755, 756, 757, 758, 759, 762, 763, 764, 765, 766, 767, 768, 771, 772, 773, 775, 776, 777, 778, 779, 780, 781, 783, 784, 785, 786, 787, 788, 789, 791, 792, 798, 799, 801, 803, 804, 805, 807, 808, 809, 810, 812, 813, 814, 816, 817, 819, 820, 821, 822, 823, 824, 825, 827, 828, 831, 833, 834, 835, 836, 837, 838, 844, 845, 846, 847, 851, 852, 854, 858, 859, 861, 862, 866, 868, 869, 870, 871, 873, 874, 875, 877, 880, 883, 886, 887, 889, 890, 891, 892, 893, 895, 898, 900, 902, 903, 904, 905, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 918, 920, 921, 922, 923, 924, 926, 927, 929, 930, 931, 932, 933, 935, 937, 939, 940, 942, 943, 945, 946, 948, 949, 950, 951, 952, 953, 955, 956, 957, 959, 960, 962, 964, 965, 968, 969, 970, 972, 973, 974, 975, 976, 977, 978, 979, 984, 985, 986, 987, 989, 991, 992, 993, 997, 999, 1000, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1016, 1017, 1018, 1020, 1021, 1023, 1025, 1026, 1027, 1029, 1030, 1031, 1032, 1034, 1036, 1037, 1038, 1052, 1053, 1054, 1055, 1056, 1058, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1072, 1073, 1074, 1076, 1078, 1079, 1080, 1081, 1082, 1083, 1085, 1086, 1087, 1089, 1090, 1091, 1093, 1095, 1096, 1097, 1099, 1101, 1102, 1103, 1105, 1106, 1107, 1108, 1112, 1113, 1114, 1115, 1117, 1118, 1119, 1120, 1121, 1124, 1129, 1130, 1131, 1132, 1134, 1135, 1136, 1137, 1139, 1140, 1142, 1143, 1144, 1145, 1147, 1148, 1150, 1151, 1153, 1154, 1156, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1167, 1168, 1171, 1172, 1173, 1174, 1175, 1177, 1178, 1180, 1181, 1182, 1183, 1185, 1187, 1191, 1193, 1195, 1196, 1199, 1200, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1213, 1214, 1216, 1217, 1219, 1220, 1222, 1224, 1225, 1226, 1228, 1230, 1231, 1232, 1233, 1234, 1237, 1238, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1254, 1258, 1259, 1261, 1262, 1263, 1264, 1265, 1266, 1268, 1269, 1270, 1271, 1272, 1273, 1275, 1277, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1287, 1288, 1289, 1290, 1294, 1297, 1298, 1299, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1325, 1326, 1330, 1332, 1334, 1335, 1336, 1339, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1353, 1355, 1357, 1358, 1362, 1366, 1367, 1368, 1369, 1371, 1372, 1374, 1375, 1376, 1377, 1378, 1379, 1381, 1382, 1384, 1385, 1386, 1387, 1388, 1390, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1400, 1401, 1406, 1408, 1409, 1410, 1414, 1416, 1417, 1418, 1419, 1420, 1421, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1434, 1435, 1436, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1449, 1451, 1454, 1458, 1462, 1463, 1466, 1467, 1468, 1469, 1470, 1471, 1473, 1478, 1479, 1480, 1481, 1486, 1489, 1492, 1493, 1495, 1496, 1497, 1500, 1503, 1504, 1508, 1509, 1511, 1512, 1513, 1515, 1519, 1521, 1525, 1526, 1527, 1528, 1531, 1532, 1535, 1536, 1537, 1540, 1541, 1542, 1547, 1550, 1551, 1552, 1554, 1555, 1558, 1559, 1561, 1562, 1563, 1564, 1565, 1566, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1579, 1580, 1582, 1583, 1585, 1586, 1587, 1589, 1590, 1591, 1593, 1594, 1595, 1597, 1598, 1599, 1610, 1611, 1612, 1613, 1614, 1615, 1620, 1622, 1623, 1624, 1625, 1627, 1629, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1639, 1641, 1642, 1644, 1646, 1647, 1648, 1649, 1652, 1653, 1654, 1655, 1658, 1659, 1661, 1662, 1663, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1674, 1675, 1676, 1677, 1678, 1679, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1689, 1692, 1693, 1694, 1695, 1697, 1698, 1699, 1700, 1701, 1702, 1704, 1705, 1706, 1707, 1708, 1712, 1714, 1715, 1717, 1718, 1719, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1731, 1732, 1733, 1734, 1735, 1736, 1738, 1741, 1742, 1743, 1745, 1747, 1748, 1749, 1752, 1753, 1754, 1755, 1756, 1758, 1759, 1760, 1761, 1762, 1764, 1765, 1766, 1767, 1768, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1784, 1785, 1786, 1787, 1790, 1792, 1793, 1795, 1797, 1798, 1799, 1801, 1803, 1805, 1808, 1811, 1812, 1814, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1832, 1836, 1837, 1840, 1842, 1843, 1844, 1845, 1846, 1847, 1849, 1851, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1875, 1877, 1878, 1880, 1882, 1883, 1884, 1886, 1887, 1889, 1890, 1891, 1894, 1895, 1896, 1898, 1899, 1900, 1903, 1904, 1905, 1907, 1909, 1910, 1911, 1912, 1913, 1916, 1920, 1924, 1926, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1944, 1945, 1946, 1947, 1948, 1950, 1952, 1954, 1955, 1957, 1958, 1960, 1961, 1962, 1963, 1965, 1966, 1967, 1969, 1970, 1971, 1972, 1974, 1976, 1978, 1979, 1983, 1985, 1989, 1990, 1994]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1329/1329 [05:58<00:00,  2.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1330/1330 [01:38<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['样本id' 'A1' 'A2' 'A3' 'A4' 'A5' 'A6' 'A7' 'A8' 'A9' 'A10' 'A11' 'A12'\n",
      " 'A13' 'A14' 'A15' 'A16' 'A17' 'A18' 'A19' 'A20' 'A21' 'A22' 'A23' 'A24'\n",
      " 'A25' 'A26' 'A27' 'A28' 'B1' 'B2' 'B3' 'B4' 'B5' 'B6' 'B7' 'B8' 'B9'\n",
      " 'B10' 'B11' 'B12' 'B13' 'B14' 'target']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['样本id_difference' 'A1_difference' 'A2_difference' 'A3_difference'\n",
      " 'A4_difference' 'A5_difference' 'A6_difference' 'A7_difference'\n",
      " 'A8_difference' 'A9_difference' 'A10_difference' 'A11_difference'\n",
      " 'A12_difference' 'A13_difference' 'A14_difference' 'A15_difference'\n",
      " 'A16_difference' 'A17_difference' 'A18_difference' 'A19_difference'\n",
      " 'A20_difference' 'A21_difference' 'A22_difference' 'A23_difference'\n",
      " 'A24_difference' 'A25_difference' 'A26_difference' 'A27_difference'\n",
      " 'A28_difference' 'B1_difference' 'B2_difference' 'B3_difference'\n",
      " 'B4_difference' 'B5_difference' 'B6_difference' 'B7_difference'\n",
      " 'B8_difference' 'B9_difference' 'B10_difference' 'B11_difference'\n",
      " 'B12_difference' 'B13_difference' 'B14_difference' '样本id' 'A1' 'A2' 'A3'\n",
      " 'A4' 'A5' 'A6' 'A7' 'A8' 'A9' 'A10' 'A11' 'A12' 'A13' 'A14' 'A15' 'A16'\n",
      " 'A17' 'A18' 'A19' 'A20' 'A21' 'A22' 'A23' 'A24' 'A25' 'A26' 'A27' 'A28'\n",
      " 'B1' 'B2' 'B3' 'B4' 'B5' 'B6' 'B7' 'B8' 'B9' 'B10' 'B11' 'B12' 'B13'\n",
      " 'B14']\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[5]\ttraining's l2: 0.00146183\tvalid_1's l2: 0.00146809\n",
      "[10]\ttraining's l2: 0.00136585\tvalid_1's l2: 0.0013718\n",
      "[15]\ttraining's l2: 0.00128414\tvalid_1's l2: 0.00128984\n",
      "[20]\ttraining's l2: 0.00120419\tvalid_1's l2: 0.00120958\n",
      "[25]\ttraining's l2: 0.00113691\tvalid_1's l2: 0.00114209\n",
      "[30]\ttraining's l2: 0.00107141\tvalid_1's l2: 0.00107635\n",
      "[35]\ttraining's l2: 0.00101139\tvalid_1's l2: 0.00101605\n",
      "[40]\ttraining's l2: 0.000957474\tvalid_1's l2: 0.00096193\n",
      "[45]\ttraining's l2: 0.000908726\tvalid_1's l2: 0.000912977\n",
      "[50]\ttraining's l2: 0.000864608\tvalid_1's l2: 0.000868677\n",
      "[55]\ttraining's l2: 0.000824426\tvalid_1's l2: 0.000828328\n",
      "[60]\ttraining's l2: 0.000787991\tvalid_1's l2: 0.000791734\n",
      "[65]\ttraining's l2: 0.0007546\tvalid_1's l2: 0.000758187\n",
      "[70]\ttraining's l2: 0.000724158\tvalid_1's l2: 0.000727607\n",
      "[75]\ttraining's l2: 0.00069741\tvalid_1's l2: 0.000700743\n",
      "[80]\ttraining's l2: 0.000672239\tvalid_1's l2: 0.000675455\n",
      "[85]\ttraining's l2: 0.000650606\tvalid_1's l2: 0.000653719\n",
      "[90]\ttraining's l2: 0.000629823\tvalid_1's l2: 0.000632822\n",
      "[95]\ttraining's l2: 0.000610097\tvalid_1's l2: 0.000612999\n",
      "[100]\ttraining's l2: 0.000592066\tvalid_1's l2: 0.000594861\n",
      "[105]\ttraining's l2: 0.000575534\tvalid_1's l2: 0.000578239\n",
      "[110]\ttraining's l2: 0.000560983\tvalid_1's l2: 0.000563614\n",
      "[115]\ttraining's l2: 0.000545629\tvalid_1's l2: 0.000548178\n",
      "[120]\ttraining's l2: 0.000532686\tvalid_1's l2: 0.000535171\n",
      "[125]\ttraining's l2: 0.000520763\tvalid_1's l2: 0.000523184\n",
      "[130]\ttraining's l2: 0.000508615\tvalid_1's l2: 0.000510972\n",
      "[135]\ttraining's l2: 0.000497352\tvalid_1's l2: 0.000499637\n",
      "[140]\ttraining's l2: 0.000487324\tvalid_1's l2: 0.000489555\n",
      "[145]\ttraining's l2: 0.000477631\tvalid_1's l2: 0.000479798\n",
      "[150]\ttraining's l2: 0.000468941\tvalid_1's l2: 0.000471058\n",
      "[155]\ttraining's l2: 0.00046059\tvalid_1's l2: 0.000462637\n",
      "[160]\ttraining's l2: 0.000452731\tvalid_1's l2: 0.000454713\n",
      "[165]\ttraining's l2: 0.000445418\tvalid_1's l2: 0.000447339\n",
      "[170]\ttraining's l2: 0.000438061\tvalid_1's l2: 0.000439934\n",
      "[175]\ttraining's l2: 0.000431555\tvalid_1's l2: 0.000433365\n",
      "[180]\ttraining's l2: 0.000425395\tvalid_1's l2: 0.000427147\n",
      "[185]\ttraining's l2: 0.00042002\tvalid_1's l2: 0.000421734\n",
      "[190]\ttraining's l2: 0.000414147\tvalid_1's l2: 0.00041584\n",
      "[195]\ttraining's l2: 0.000409185\tvalid_1's l2: 0.000410864\n",
      "[200]\ttraining's l2: 0.000404332\tvalid_1's l2: 0.00040598\n",
      "[205]\ttraining's l2: 0.00039917\tvalid_1's l2: 0.000400792\n",
      "[210]\ttraining's l2: 0.0003952\tvalid_1's l2: 0.000396809\n",
      "[215]\ttraining's l2: 0.000390998\tvalid_1's l2: 0.000392582\n",
      "[220]\ttraining's l2: 0.000387045\tvalid_1's l2: 0.000388605\n",
      "[225]\ttraining's l2: 0.000383367\tvalid_1's l2: 0.0003849\n",
      "[230]\ttraining's l2: 0.000379702\tvalid_1's l2: 0.000381197\n",
      "[235]\ttraining's l2: 0.000376052\tvalid_1's l2: 0.000377522\n",
      "[240]\ttraining's l2: 0.000372674\tvalid_1's l2: 0.000374113\n",
      "[245]\ttraining's l2: 0.000369642\tvalid_1's l2: 0.000371066\n",
      "[250]\ttraining's l2: 0.000366629\tvalid_1's l2: 0.00036804\n",
      "[255]\ttraining's l2: 0.000363873\tvalid_1's l2: 0.000365264\n",
      "[260]\ttraining's l2: 0.000360906\tvalid_1's l2: 0.000362295\n",
      "[265]\ttraining's l2: 0.000358541\tvalid_1's l2: 0.000359936\n",
      "[270]\ttraining's l2: 0.000355433\tvalid_1's l2: 0.000356819\n",
      "[275]\ttraining's l2: 0.000352313\tvalid_1's l2: 0.00035369\n",
      "[280]\ttraining's l2: 0.000349842\tvalid_1's l2: 0.000351214\n",
      "[285]\ttraining's l2: 0.000347345\tvalid_1's l2: 0.000348718\n",
      "[290]\ttraining's l2: 0.000344902\tvalid_1's l2: 0.000346273\n",
      "[295]\ttraining's l2: 0.000342735\tvalid_1's l2: 0.000344108\n",
      "[300]\ttraining's l2: 0.000340221\tvalid_1's l2: 0.000341596\n",
      "[305]\ttraining's l2: 0.000337879\tvalid_1's l2: 0.000339264\n",
      "[310]\ttraining's l2: 0.000335405\tvalid_1's l2: 0.000336786\n",
      "[315]\ttraining's l2: 0.000333228\tvalid_1's l2: 0.000334611\n",
      "[320]\ttraining's l2: 0.000331084\tvalid_1's l2: 0.000332469\n",
      "[325]\ttraining's l2: 0.0003288\tvalid_1's l2: 0.000330189\n",
      "[330]\ttraining's l2: 0.000326856\tvalid_1's l2: 0.000328239\n",
      "[335]\ttraining's l2: 0.000324941\tvalid_1's l2: 0.000326332\n",
      "[340]\ttraining's l2: 0.000323234\tvalid_1's l2: 0.000324635\n",
      "[345]\ttraining's l2: 0.000321312\tvalid_1's l2: 0.000322721\n",
      "[350]\ttraining's l2: 0.000319479\tvalid_1's l2: 0.00032091\n",
      "[355]\ttraining's l2: 0.000317615\tvalid_1's l2: 0.000319057\n",
      "[360]\ttraining's l2: 0.000315941\tvalid_1's l2: 0.000317396\n",
      "[365]\ttraining's l2: 0.000314273\tvalid_1's l2: 0.000315742\n",
      "[370]\ttraining's l2: 0.000312693\tvalid_1's l2: 0.000314168\n",
      "[375]\ttraining's l2: 0.000311176\tvalid_1's l2: 0.000312662\n",
      "[380]\ttraining's l2: 0.000309507\tvalid_1's l2: 0.000310998\n",
      "[385]\ttraining's l2: 0.000307788\tvalid_1's l2: 0.000309277\n",
      "[390]\ttraining's l2: 0.000306081\tvalid_1's l2: 0.000307574\n",
      "[395]\ttraining's l2: 0.000304656\tvalid_1's l2: 0.000306157\n",
      "[400]\ttraining's l2: 0.000302975\tvalid_1's l2: 0.00030448\n",
      "[405]\ttraining's l2: 0.000301395\tvalid_1's l2: 0.000302905\n",
      "[410]\ttraining's l2: 0.000300141\tvalid_1's l2: 0.000301655\n",
      "[415]\ttraining's l2: 0.000298729\tvalid_1's l2: 0.000300251\n",
      "[420]\ttraining's l2: 0.000297273\tvalid_1's l2: 0.000298794\n",
      "[425]\ttraining's l2: 0.000295734\tvalid_1's l2: 0.000297251\n",
      "[430]\ttraining's l2: 0.000294392\tvalid_1's l2: 0.000295924\n",
      "[435]\ttraining's l2: 0.00029323\tvalid_1's l2: 0.000294774\n",
      "[440]\ttraining's l2: 0.000292046\tvalid_1's l2: 0.000293596\n",
      "[445]\ttraining's l2: 0.00029077\tvalid_1's l2: 0.000292314\n",
      "[450]\ttraining's l2: 0.000289535\tvalid_1's l2: 0.000291086\n",
      "[455]\ttraining's l2: 0.000288253\tvalid_1's l2: 0.0002898\n",
      "[460]\ttraining's l2: 0.00028717\tvalid_1's l2: 0.00028872\n",
      "[465]\ttraining's l2: 0.000286026\tvalid_1's l2: 0.000287574\n",
      "[470]\ttraining's l2: 0.00028492\tvalid_1's l2: 0.000286479\n",
      "[475]\ttraining's l2: 0.00028388\tvalid_1's l2: 0.000285443\n",
      "[480]\ttraining's l2: 0.000282729\tvalid_1's l2: 0.000284295\n",
      "[485]\ttraining's l2: 0.000281748\tvalid_1's l2: 0.000283315\n",
      "[490]\ttraining's l2: 0.000280602\tvalid_1's l2: 0.000282165\n",
      "[495]\ttraining's l2: 0.000279579\tvalid_1's l2: 0.000281141\n",
      "[500]\ttraining's l2: 0.000278682\tvalid_1's l2: 0.000280243\n",
      "[505]\ttraining's l2: 0.000277706\tvalid_1's l2: 0.000279271\n",
      "[510]\ttraining's l2: 0.000276746\tvalid_1's l2: 0.000278312\n",
      "[515]\ttraining's l2: 0.000275764\tvalid_1's l2: 0.000277331\n",
      "[520]\ttraining's l2: 0.000274788\tvalid_1's l2: 0.000276352\n",
      "[525]\ttraining's l2: 0.000273966\tvalid_1's l2: 0.000275538\n",
      "[530]\ttraining's l2: 0.000273022\tvalid_1's l2: 0.000274591\n",
      "[535]\ttraining's l2: 0.000271989\tvalid_1's l2: 0.000273553\n",
      "[540]\ttraining's l2: 0.000271145\tvalid_1's l2: 0.000272718\n",
      "[545]\ttraining's l2: 0.000270323\tvalid_1's l2: 0.000271905\n",
      "[550]\ttraining's l2: 0.000269492\tvalid_1's l2: 0.000271081\n",
      "[555]\ttraining's l2: 0.000268705\tvalid_1's l2: 0.000270298\n",
      "[560]\ttraining's l2: 0.000267864\tvalid_1's l2: 0.000269457\n",
      "[565]\ttraining's l2: 0.000267061\tvalid_1's l2: 0.000268651\n",
      "[570]\ttraining's l2: 0.000266359\tvalid_1's l2: 0.000267957\n",
      "[575]\ttraining's l2: 0.000265541\tvalid_1's l2: 0.000267136\n",
      "[580]\ttraining's l2: 0.000264705\tvalid_1's l2: 0.000266298\n",
      "[585]\ttraining's l2: 0.000263931\tvalid_1's l2: 0.000265524\n",
      "[590]\ttraining's l2: 0.000263215\tvalid_1's l2: 0.00026481\n",
      "[595]\ttraining's l2: 0.000262437\tvalid_1's l2: 0.000264035\n",
      "[600]\ttraining's l2: 0.000261647\tvalid_1's l2: 0.000263241\n",
      "[605]\ttraining's l2: 0.000260906\tvalid_1's l2: 0.000262498\n",
      "[610]\ttraining's l2: 0.000260314\tvalid_1's l2: 0.00026191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[615]\ttraining's l2: 0.000259571\tvalid_1's l2: 0.000261166\n",
      "[620]\ttraining's l2: 0.000258875\tvalid_1's l2: 0.000260473\n",
      "[625]\ttraining's l2: 0.000258115\tvalid_1's l2: 0.00025971\n",
      "[630]\ttraining's l2: 0.000257371\tvalid_1's l2: 0.00025897\n",
      "[635]\ttraining's l2: 0.000256673\tvalid_1's l2: 0.000258272\n",
      "[640]\ttraining's l2: 0.000256045\tvalid_1's l2: 0.000257643\n",
      "[645]\ttraining's l2: 0.000255435\tvalid_1's l2: 0.000257035\n",
      "[650]\ttraining's l2: 0.000254689\tvalid_1's l2: 0.000256284\n",
      "[655]\ttraining's l2: 0.000254033\tvalid_1's l2: 0.000255623\n",
      "[660]\ttraining's l2: 0.000253264\tvalid_1's l2: 0.000254847\n",
      "[665]\ttraining's l2: 0.000252665\tvalid_1's l2: 0.000254252\n",
      "[670]\ttraining's l2: 0.000252082\tvalid_1's l2: 0.000253674\n",
      "[675]\ttraining's l2: 0.000251488\tvalid_1's l2: 0.000253085\n",
      "[680]\ttraining's l2: 0.000250908\tvalid_1's l2: 0.000252504\n",
      "[685]\ttraining's l2: 0.000250273\tvalid_1's l2: 0.000251874\n",
      "[690]\ttraining's l2: 0.000249689\tvalid_1's l2: 0.000251287\n",
      "[695]\ttraining's l2: 0.000249162\tvalid_1's l2: 0.000250758\n",
      "[700]\ttraining's l2: 0.000248619\tvalid_1's l2: 0.000250218\n",
      "[705]\ttraining's l2: 0.000248049\tvalid_1's l2: 0.00024965\n",
      "[710]\ttraining's l2: 0.000247537\tvalid_1's l2: 0.000249139\n",
      "[715]\ttraining's l2: 0.000246958\tvalid_1's l2: 0.00024856\n",
      "[720]\ttraining's l2: 0.000246452\tvalid_1's l2: 0.000248055\n",
      "[725]\ttraining's l2: 0.000245957\tvalid_1's l2: 0.000247558\n",
      "[730]\ttraining's l2: 0.000245374\tvalid_1's l2: 0.000246974\n",
      "[735]\ttraining's l2: 0.00024484\tvalid_1's l2: 0.000246436\n",
      "[740]\ttraining's l2: 0.000244349\tvalid_1's l2: 0.000245946\n",
      "[745]\ttraining's l2: 0.000243849\tvalid_1's l2: 0.000245444\n",
      "[750]\ttraining's l2: 0.000243264\tvalid_1's l2: 0.000244865\n",
      "[755]\ttraining's l2: 0.000242712\tvalid_1's l2: 0.000244309\n",
      "[760]\ttraining's l2: 0.000242196\tvalid_1's l2: 0.000243789\n",
      "[765]\ttraining's l2: 0.000241673\tvalid_1's l2: 0.000243259\n",
      "[770]\ttraining's l2: 0.000241117\tvalid_1's l2: 0.000242706\n",
      "[775]\ttraining's l2: 0.000240529\tvalid_1's l2: 0.000242125\n",
      "[780]\ttraining's l2: 0.000240071\tvalid_1's l2: 0.000241668\n",
      "[785]\ttraining's l2: 0.000239608\tvalid_1's l2: 0.000241199\n",
      "[790]\ttraining's l2: 0.000239067\tvalid_1's l2: 0.000240661\n",
      "[795]\ttraining's l2: 0.000238578\tvalid_1's l2: 0.000240172\n",
      "[800]\ttraining's l2: 0.00023812\tvalid_1's l2: 0.000239719\n",
      "[805]\ttraining's l2: 0.000237582\tvalid_1's l2: 0.00023918\n",
      "[810]\ttraining's l2: 0.00023707\tvalid_1's l2: 0.000238667\n",
      "[815]\ttraining's l2: 0.000236567\tvalid_1's l2: 0.000238166\n",
      "[820]\ttraining's l2: 0.000236107\tvalid_1's l2: 0.000237709\n",
      "[825]\ttraining's l2: 0.000235657\tvalid_1's l2: 0.000237263\n",
      "[830]\ttraining's l2: 0.00023527\tvalid_1's l2: 0.000236877\n",
      "[835]\ttraining's l2: 0.000234801\tvalid_1's l2: 0.000236411\n",
      "[840]\ttraining's l2: 0.000234396\tvalid_1's l2: 0.000236005\n",
      "[845]\ttraining's l2: 0.000233894\tvalid_1's l2: 0.0002355\n",
      "[850]\ttraining's l2: 0.000233351\tvalid_1's l2: 0.000234962\n",
      "[855]\ttraining's l2: 0.000232912\tvalid_1's l2: 0.000234518\n",
      "[860]\ttraining's l2: 0.000232426\tvalid_1's l2: 0.00023403\n",
      "[865]\ttraining's l2: 0.000232049\tvalid_1's l2: 0.00023365\n",
      "[870]\ttraining's l2: 0.000231601\tvalid_1's l2: 0.000233197\n",
      "[875]\ttraining's l2: 0.000231245\tvalid_1's l2: 0.000232839\n",
      "[880]\ttraining's l2: 0.000230865\tvalid_1's l2: 0.000232459\n",
      "[885]\ttraining's l2: 0.000230439\tvalid_1's l2: 0.000232029\n",
      "[890]\ttraining's l2: 0.000230011\tvalid_1's l2: 0.0002316\n",
      "[895]\ttraining's l2: 0.000229572\tvalid_1's l2: 0.000231156\n",
      "[900]\ttraining's l2: 0.000229144\tvalid_1's l2: 0.000230727\n",
      "[905]\ttraining's l2: 0.000228748\tvalid_1's l2: 0.00023033\n",
      "[910]\ttraining's l2: 0.00022845\tvalid_1's l2: 0.000230036\n",
      "[915]\ttraining's l2: 0.000228028\tvalid_1's l2: 0.00022961\n",
      "[920]\ttraining's l2: 0.000227619\tvalid_1's l2: 0.000229203\n",
      "[925]\ttraining's l2: 0.000227189\tvalid_1's l2: 0.000228777\n",
      "[930]\ttraining's l2: 0.000226828\tvalid_1's l2: 0.000228418\n",
      "[935]\ttraining's l2: 0.000226469\tvalid_1's l2: 0.00022806\n",
      "[940]\ttraining's l2: 0.000226091\tvalid_1's l2: 0.000227681\n",
      "[945]\ttraining's l2: 0.000225709\tvalid_1's l2: 0.000227299\n",
      "[950]\ttraining's l2: 0.000225341\tvalid_1's l2: 0.000226936\n",
      "[955]\ttraining's l2: 0.00022501\tvalid_1's l2: 0.000226614\n",
      "[960]\ttraining's l2: 0.000224581\tvalid_1's l2: 0.000226188\n",
      "[965]\ttraining's l2: 0.000224232\tvalid_1's l2: 0.00022584\n",
      "[970]\ttraining's l2: 0.000223822\tvalid_1's l2: 0.000225427\n",
      "[975]\ttraining's l2: 0.000223374\tvalid_1's l2: 0.000224981\n",
      "[980]\ttraining's l2: 0.000222896\tvalid_1's l2: 0.000224505\n",
      "[985]\ttraining's l2: 0.000222512\tvalid_1's l2: 0.00022412\n",
      "[990]\ttraining's l2: 0.00022215\tvalid_1's l2: 0.000223759\n",
      "[995]\ttraining's l2: 0.00022174\tvalid_1's l2: 0.000223348\n",
      "[1000]\ttraining's l2: 0.000221375\tvalid_1's l2: 0.000222982\n",
      "[1005]\ttraining's l2: 0.000221059\tvalid_1's l2: 0.000222667\n",
      "[1010]\ttraining's l2: 0.000220628\tvalid_1's l2: 0.000222238\n",
      "[1015]\ttraining's l2: 0.000220257\tvalid_1's l2: 0.000221866\n",
      "[1020]\ttraining's l2: 0.000219898\tvalid_1's l2: 0.000221513\n",
      "[1025]\ttraining's l2: 0.000219517\tvalid_1's l2: 0.000221132\n",
      "[1030]\ttraining's l2: 0.000219086\tvalid_1's l2: 0.000220698\n",
      "[1035]\ttraining's l2: 0.000218706\tvalid_1's l2: 0.000220314\n",
      "[1040]\ttraining's l2: 0.000218414\tvalid_1's l2: 0.000220022\n",
      "[1045]\ttraining's l2: 0.000218102\tvalid_1's l2: 0.00021971\n",
      "[1050]\ttraining's l2: 0.000217729\tvalid_1's l2: 0.000219332\n",
      "[1055]\ttraining's l2: 0.000217408\tvalid_1's l2: 0.000219016\n",
      "[1060]\ttraining's l2: 0.000217101\tvalid_1's l2: 0.00021871\n",
      "[1065]\ttraining's l2: 0.000216718\tvalid_1's l2: 0.000218326\n",
      "[1070]\ttraining's l2: 0.000216344\tvalid_1's l2: 0.000217954\n",
      "[1075]\ttraining's l2: 0.000216016\tvalid_1's l2: 0.000217628\n",
      "[1080]\ttraining's l2: 0.000215686\tvalid_1's l2: 0.000217297\n",
      "[1085]\ttraining's l2: 0.00021536\tvalid_1's l2: 0.000216969\n",
      "[1090]\ttraining's l2: 0.000215063\tvalid_1's l2: 0.000216672\n",
      "[1095]\ttraining's l2: 0.000214725\tvalid_1's l2: 0.000216336\n",
      "[1100]\ttraining's l2: 0.000214428\tvalid_1's l2: 0.00021604\n",
      "[1105]\ttraining's l2: 0.000214135\tvalid_1's l2: 0.000215748\n",
      "[1110]\ttraining's l2: 0.000213812\tvalid_1's l2: 0.000215425\n",
      "[1115]\ttraining's l2: 0.000213535\tvalid_1's l2: 0.000215151\n",
      "[1120]\ttraining's l2: 0.000213195\tvalid_1's l2: 0.000214814\n",
      "[1125]\ttraining's l2: 0.000212909\tvalid_1's l2: 0.000214525\n",
      "[1130]\ttraining's l2: 0.000212572\tvalid_1's l2: 0.000214185\n",
      "[1135]\ttraining's l2: 0.000212294\tvalid_1's l2: 0.000213908\n",
      "[1140]\ttraining's l2: 0.000212025\tvalid_1's l2: 0.000213639\n",
      "[1145]\ttraining's l2: 0.000211734\tvalid_1's l2: 0.000213345\n",
      "[1150]\ttraining's l2: 0.000211488\tvalid_1's l2: 0.000213099\n",
      "[1155]\ttraining's l2: 0.00021121\tvalid_1's l2: 0.000212825\n",
      "[1160]\ttraining's l2: 0.000210876\tvalid_1's l2: 0.00021249\n",
      "[1165]\ttraining's l2: 0.000210518\tvalid_1's l2: 0.000212131\n",
      "[1170]\ttraining's l2: 0.000210232\tvalid_1's l2: 0.000211844\n",
      "[1175]\ttraining's l2: 0.000209896\tvalid_1's l2: 0.000211504\n",
      "[1180]\ttraining's l2: 0.000209635\tvalid_1's l2: 0.000211245\n",
      "[1185]\ttraining's l2: 0.00020937\tvalid_1's l2: 0.000210983\n",
      "[1190]\ttraining's l2: 0.000209035\tvalid_1's l2: 0.00021065\n",
      "[1195]\ttraining's l2: 0.00020875\tvalid_1's l2: 0.000210366\n",
      "[1200]\ttraining's l2: 0.000208419\tvalid_1's l2: 0.000210031\n",
      "[1205]\ttraining's l2: 0.000208163\tvalid_1's l2: 0.000209772\n",
      "[1210]\ttraining's l2: 0.000207903\tvalid_1's l2: 0.000209513\n",
      "[1215]\ttraining's l2: 0.000207639\tvalid_1's l2: 0.000209248\n",
      "[1220]\ttraining's l2: 0.00020736\tvalid_1's l2: 0.000208974\n",
      "[1225]\ttraining's l2: 0.000207103\tvalid_1's l2: 0.000208719\n",
      "[1230]\ttraining's l2: 0.000206819\tvalid_1's l2: 0.000208432\n",
      "[1235]\ttraining's l2: 0.000206475\tvalid_1's l2: 0.000208091\n",
      "[1240]\ttraining's l2: 0.000206187\tvalid_1's l2: 0.000207808\n",
      "[1245]\ttraining's l2: 0.000205957\tvalid_1's l2: 0.00020758\n",
      "[1250]\ttraining's l2: 0.000205685\tvalid_1's l2: 0.000207302\n",
      "[1255]\ttraining's l2: 0.000205387\tvalid_1's l2: 0.000207003\n",
      "[1260]\ttraining's l2: 0.0002051\tvalid_1's l2: 0.000206718\n",
      "[1265]\ttraining's l2: 0.000204852\tvalid_1's l2: 0.000206471\n",
      "[1270]\ttraining's l2: 0.000204578\tvalid_1's l2: 0.000206197\n",
      "[1275]\ttraining's l2: 0.000204317\tvalid_1's l2: 0.000205936\n",
      "[1280]\ttraining's l2: 0.000204091\tvalid_1's l2: 0.00020571\n",
      "[1285]\ttraining's l2: 0.000203834\tvalid_1's l2: 0.000205453\n",
      "[1290]\ttraining's l2: 0.000203529\tvalid_1's l2: 0.000205146\n",
      "[1295]\ttraining's l2: 0.00020326\tvalid_1's l2: 0.000204878\n",
      "[1300]\ttraining's l2: 0.000203033\tvalid_1's l2: 0.000204659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1305]\ttraining's l2: 0.00020274\tvalid_1's l2: 0.000204367\n",
      "[1310]\ttraining's l2: 0.000202419\tvalid_1's l2: 0.000204044\n",
      "[1315]\ttraining's l2: 0.000202175\tvalid_1's l2: 0.000203801\n",
      "[1320]\ttraining's l2: 0.000201943\tvalid_1's l2: 0.000203569\n",
      "[1325]\ttraining's l2: 0.000201727\tvalid_1's l2: 0.000203348\n",
      "[1330]\ttraining's l2: 0.0002015\tvalid_1's l2: 0.00020312\n",
      "[1335]\ttraining's l2: 0.00020123\tvalid_1's l2: 0.000202849\n",
      "[1340]\ttraining's l2: 0.000200953\tvalid_1's l2: 0.000202567\n",
      "[1345]\ttraining's l2: 0.000200627\tvalid_1's l2: 0.000202241\n",
      "[1350]\ttraining's l2: 0.000200403\tvalid_1's l2: 0.000202018\n",
      "[1355]\ttraining's l2: 0.000200118\tvalid_1's l2: 0.000201731\n",
      "[1360]\ttraining's l2: 0.000199863\tvalid_1's l2: 0.000201474\n",
      "[1365]\ttraining's l2: 0.000199613\tvalid_1's l2: 0.00020122\n",
      "[1370]\ttraining's l2: 0.000199295\tvalid_1's l2: 0.000200901\n",
      "[1375]\ttraining's l2: 0.00019898\tvalid_1's l2: 0.000200586\n",
      "[1380]\ttraining's l2: 0.000198675\tvalid_1's l2: 0.00020028\n",
      "[1385]\ttraining's l2: 0.000198397\tvalid_1's l2: 0.000200002\n",
      "[1390]\ttraining's l2: 0.00019816\tvalid_1's l2: 0.00019976\n",
      "[1395]\ttraining's l2: 0.000197898\tvalid_1's l2: 0.000199496\n",
      "[1400]\ttraining's l2: 0.000197655\tvalid_1's l2: 0.00019925\n",
      "[1405]\ttraining's l2: 0.000197398\tvalid_1's l2: 0.000198992\n",
      "[1410]\ttraining's l2: 0.000197218\tvalid_1's l2: 0.000198817\n",
      "[1415]\ttraining's l2: 0.000196948\tvalid_1's l2: 0.000198548\n",
      "[1420]\ttraining's l2: 0.000196737\tvalid_1's l2: 0.000198336\n",
      "[1425]\ttraining's l2: 0.000196529\tvalid_1's l2: 0.000198128\n",
      "[1430]\ttraining's l2: 0.000196223\tvalid_1's l2: 0.00019782\n",
      "[1435]\ttraining's l2: 0.000195903\tvalid_1's l2: 0.000197496\n",
      "[1440]\ttraining's l2: 0.000195692\tvalid_1's l2: 0.000197283\n",
      "[1445]\ttraining's l2: 0.000195475\tvalid_1's l2: 0.000197069\n",
      "[1450]\ttraining's l2: 0.00019517\tvalid_1's l2: 0.000196766\n",
      "[1455]\ttraining's l2: 0.000194933\tvalid_1's l2: 0.000196529\n",
      "[1460]\ttraining's l2: 0.000194738\tvalid_1's l2: 0.000196334\n",
      "[1465]\ttraining's l2: 0.000194529\tvalid_1's l2: 0.000196126\n",
      "[1470]\ttraining's l2: 0.000194273\tvalid_1's l2: 0.000195872\n",
      "[1475]\ttraining's l2: 0.000194049\tvalid_1's l2: 0.000195649\n",
      "[1480]\ttraining's l2: 0.000193796\tvalid_1's l2: 0.000195393\n",
      "[1485]\ttraining's l2: 0.00019351\tvalid_1's l2: 0.00019511\n",
      "[1490]\ttraining's l2: 0.000193275\tvalid_1's l2: 0.000194873\n",
      "[1495]\ttraining's l2: 0.000193016\tvalid_1's l2: 0.000194614\n",
      "[1500]\ttraining's l2: 0.000192792\tvalid_1's l2: 0.000194393\n",
      "[1505]\ttraining's l2: 0.000192558\tvalid_1's l2: 0.000194162\n",
      "[1510]\ttraining's l2: 0.000192308\tvalid_1's l2: 0.000193904\n",
      "[1515]\ttraining's l2: 0.000192065\tvalid_1's l2: 0.000193658\n",
      "[1520]\ttraining's l2: 0.000191883\tvalid_1's l2: 0.000193478\n",
      "[1525]\ttraining's l2: 0.000191712\tvalid_1's l2: 0.000193306\n",
      "[1530]\ttraining's l2: 0.000191492\tvalid_1's l2: 0.000193086\n",
      "[1535]\ttraining's l2: 0.000191286\tvalid_1's l2: 0.000192881\n",
      "[1540]\ttraining's l2: 0.000191064\tvalid_1's l2: 0.000192659\n",
      "[1545]\ttraining's l2: 0.000190833\tvalid_1's l2: 0.000192427\n",
      "[1550]\ttraining's l2: 0.000190602\tvalid_1's l2: 0.000192196\n",
      "[1555]\ttraining's l2: 0.000190446\tvalid_1's l2: 0.000192042\n",
      "[1560]\ttraining's l2: 0.000190212\tvalid_1's l2: 0.000191806\n",
      "[1565]\ttraining's l2: 0.00019003\tvalid_1's l2: 0.000191623\n",
      "[1570]\ttraining's l2: 0.000189822\tvalid_1's l2: 0.000191416\n",
      "[1575]\ttraining's l2: 0.000189607\tvalid_1's l2: 0.000191201\n",
      "[1580]\ttraining's l2: 0.000189346\tvalid_1's l2: 0.000190936\n",
      "[1585]\ttraining's l2: 0.000189083\tvalid_1's l2: 0.000190671\n",
      "[1590]\ttraining's l2: 0.000188836\tvalid_1's l2: 0.000190425\n",
      "[1595]\ttraining's l2: 0.000188636\tvalid_1's l2: 0.000190222\n",
      "[1600]\ttraining's l2: 0.000188422\tvalid_1's l2: 0.000190007\n",
      "[1605]\ttraining's l2: 0.000188215\tvalid_1's l2: 0.000189797\n",
      "[1610]\ttraining's l2: 0.000188009\tvalid_1's l2: 0.000189588\n",
      "[1615]\ttraining's l2: 0.000187816\tvalid_1's l2: 0.000189394\n",
      "[1620]\ttraining's l2: 0.000187614\tvalid_1's l2: 0.000189187\n",
      "[1625]\ttraining's l2: 0.000187421\tvalid_1's l2: 0.000188992\n",
      "[1630]\ttraining's l2: 0.00018713\tvalid_1's l2: 0.0001887\n",
      "[1635]\ttraining's l2: 0.000186898\tvalid_1's l2: 0.000188469\n",
      "[1640]\ttraining's l2: 0.000186677\tvalid_1's l2: 0.000188247\n",
      "[1645]\ttraining's l2: 0.000186466\tvalid_1's l2: 0.000188034\n",
      "[1650]\ttraining's l2: 0.00018627\tvalid_1's l2: 0.000187836\n",
      "[1655]\ttraining's l2: 0.000186059\tvalid_1's l2: 0.000187623\n",
      "[1660]\ttraining's l2: 0.000185898\tvalid_1's l2: 0.000187459\n",
      "[1665]\ttraining's l2: 0.000185698\tvalid_1's l2: 0.000187256\n",
      "[1670]\ttraining's l2: 0.000185516\tvalid_1's l2: 0.000187074\n",
      "[1675]\ttraining's l2: 0.000185323\tvalid_1's l2: 0.000186877\n",
      "[1680]\ttraining's l2: 0.000185105\tvalid_1's l2: 0.000186657\n",
      "[1685]\ttraining's l2: 0.000184914\tvalid_1's l2: 0.000186465\n",
      "[1690]\ttraining's l2: 0.000184724\tvalid_1's l2: 0.000186274\n",
      "[1695]\ttraining's l2: 0.000184528\tvalid_1's l2: 0.000186072\n",
      "[1700]\ttraining's l2: 0.00018436\tvalid_1's l2: 0.000185903\n",
      "[1705]\ttraining's l2: 0.00018417\tvalid_1's l2: 0.000185715\n",
      "[1710]\ttraining's l2: 0.000183978\tvalid_1's l2: 0.000185519\n",
      "[1715]\ttraining's l2: 0.000183826\tvalid_1's l2: 0.000185367\n",
      "[1720]\ttraining's l2: 0.000183654\tvalid_1's l2: 0.000185198\n",
      "[1725]\ttraining's l2: 0.000183473\tvalid_1's l2: 0.000185019\n",
      "[1730]\ttraining's l2: 0.000183317\tvalid_1's l2: 0.000184864\n",
      "[1735]\ttraining's l2: 0.000183137\tvalid_1's l2: 0.000184682\n",
      "[1740]\ttraining's l2: 0.00018298\tvalid_1's l2: 0.000184527\n",
      "[1745]\ttraining's l2: 0.000182794\tvalid_1's l2: 0.000184337\n",
      "[1750]\ttraining's l2: 0.00018261\tvalid_1's l2: 0.000184151\n",
      "[1755]\ttraining's l2: 0.000182449\tvalid_1's l2: 0.000183988\n",
      "[1760]\ttraining's l2: 0.000182273\tvalid_1's l2: 0.00018381\n",
      "[1765]\ttraining's l2: 0.000182113\tvalid_1's l2: 0.000183649\n",
      "[1770]\ttraining's l2: 0.000181944\tvalid_1's l2: 0.000183478\n",
      "[1775]\ttraining's l2: 0.000181763\tvalid_1's l2: 0.000183294\n",
      "[1780]\ttraining's l2: 0.000181583\tvalid_1's l2: 0.000183113\n",
      "[1785]\ttraining's l2: 0.000181407\tvalid_1's l2: 0.000182934\n",
      "[1790]\ttraining's l2: 0.000181251\tvalid_1's l2: 0.000182778\n",
      "[1795]\ttraining's l2: 0.000181074\tvalid_1's l2: 0.000182597\n",
      "[1800]\ttraining's l2: 0.000180875\tvalid_1's l2: 0.000182399\n",
      "[1805]\ttraining's l2: 0.000180672\tvalid_1's l2: 0.000182196\n",
      "[1810]\ttraining's l2: 0.000180488\tvalid_1's l2: 0.000182012\n",
      "[1815]\ttraining's l2: 0.000180347\tvalid_1's l2: 0.000181872\n",
      "[1820]\ttraining's l2: 0.000180214\tvalid_1's l2: 0.000181738\n",
      "[1825]\ttraining's l2: 0.000180032\tvalid_1's l2: 0.000181553\n",
      "[1830]\ttraining's l2: 0.000179852\tvalid_1's l2: 0.000181376\n",
      "[1835]\ttraining's l2: 0.000179673\tvalid_1's l2: 0.000181196\n",
      "[1840]\ttraining's l2: 0.00017948\tvalid_1's l2: 0.000181003\n",
      "[1845]\ttraining's l2: 0.000179292\tvalid_1's l2: 0.000180813\n",
      "[1850]\ttraining's l2: 0.000179172\tvalid_1's l2: 0.000180691\n",
      "[1855]\ttraining's l2: 0.00017899\tvalid_1's l2: 0.000180506\n",
      "[1860]\ttraining's l2: 0.000178831\tvalid_1's l2: 0.000180349\n",
      "[1865]\ttraining's l2: 0.000178649\tvalid_1's l2: 0.000180167\n",
      "[1870]\ttraining's l2: 0.000178477\tvalid_1's l2: 0.000179991\n",
      "[1875]\ttraining's l2: 0.000178286\tvalid_1's l2: 0.000179801\n",
      "[1880]\ttraining's l2: 0.000178125\tvalid_1's l2: 0.00017964\n",
      "[1885]\ttraining's l2: 0.000177945\tvalid_1's l2: 0.000179459\n",
      "[1890]\ttraining's l2: 0.000177783\tvalid_1's l2: 0.000179295\n",
      "[1895]\ttraining's l2: 0.000177646\tvalid_1's l2: 0.000179159\n",
      "[1900]\ttraining's l2: 0.000177492\tvalid_1's l2: 0.000179006\n",
      "[1905]\ttraining's l2: 0.000177328\tvalid_1's l2: 0.000178839\n",
      "[1910]\ttraining's l2: 0.000177136\tvalid_1's l2: 0.000178646\n",
      "[1915]\ttraining's l2: 0.000176948\tvalid_1's l2: 0.000178456\n",
      "[1920]\ttraining's l2: 0.000176775\tvalid_1's l2: 0.000178283\n",
      "[1925]\ttraining's l2: 0.000176584\tvalid_1's l2: 0.000178088\n",
      "[1930]\ttraining's l2: 0.000176407\tvalid_1's l2: 0.000177915\n",
      "[1935]\ttraining's l2: 0.000176225\tvalid_1's l2: 0.00017773\n",
      "[1940]\ttraining's l2: 0.000176083\tvalid_1's l2: 0.000177588\n",
      "[1945]\ttraining's l2: 0.000175958\tvalid_1's l2: 0.000177465\n",
      "[1950]\ttraining's l2: 0.000175789\tvalid_1's l2: 0.000177292\n",
      "[1955]\ttraining's l2: 0.00017563\tvalid_1's l2: 0.000177132\n",
      "[1960]\ttraining's l2: 0.000175483\tvalid_1's l2: 0.000176986\n",
      "[1965]\ttraining's l2: 0.000175317\tvalid_1's l2: 0.000176821\n",
      "[1970]\ttraining's l2: 0.00017518\tvalid_1's l2: 0.000176684\n",
      "[1975]\ttraining's l2: 0.000175042\tvalid_1's l2: 0.000176547\n",
      "[1980]\ttraining's l2: 0.000174877\tvalid_1's l2: 0.000176381\n",
      "[1985]\ttraining's l2: 0.000174747\tvalid_1's l2: 0.000176251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1990]\ttraining's l2: 0.000174598\tvalid_1's l2: 0.000176103\n",
      "[1995]\ttraining's l2: 0.000174472\tvalid_1's l2: 0.000175973\n",
      "[2000]\ttraining's l2: 0.000174317\tvalid_1's l2: 0.000175821\n",
      "[2005]\ttraining's l2: 0.000174116\tvalid_1's l2: 0.000175618\n",
      "[2010]\ttraining's l2: 0.000173969\tvalid_1's l2: 0.000175468\n",
      "[2015]\ttraining's l2: 0.000173825\tvalid_1's l2: 0.000175325\n",
      "[2020]\ttraining's l2: 0.000173718\tvalid_1's l2: 0.000175216\n",
      "[2025]\ttraining's l2: 0.000173531\tvalid_1's l2: 0.000175026\n",
      "[2030]\ttraining's l2: 0.000173338\tvalid_1's l2: 0.000174833\n",
      "[2035]\ttraining's l2: 0.000173191\tvalid_1's l2: 0.000174685\n",
      "[2040]\ttraining's l2: 0.000172987\tvalid_1's l2: 0.000174481\n",
      "[2045]\ttraining's l2: 0.000172865\tvalid_1's l2: 0.000174359\n",
      "[2050]\ttraining's l2: 0.000172729\tvalid_1's l2: 0.000174222\n",
      "[2055]\ttraining's l2: 0.000172527\tvalid_1's l2: 0.000174021\n",
      "[2060]\ttraining's l2: 0.0001724\tvalid_1's l2: 0.000173894\n",
      "[2065]\ttraining's l2: 0.000172243\tvalid_1's l2: 0.000173735\n",
      "[2070]\ttraining's l2: 0.000172114\tvalid_1's l2: 0.000173607\n",
      "[2075]\ttraining's l2: 0.000171963\tvalid_1's l2: 0.000173454\n",
      "[2080]\ttraining's l2: 0.000171796\tvalid_1's l2: 0.000173285\n",
      "[2085]\ttraining's l2: 0.000171669\tvalid_1's l2: 0.00017316\n",
      "[2090]\ttraining's l2: 0.000171485\tvalid_1's l2: 0.000172977\n",
      "[2095]\ttraining's l2: 0.000171323\tvalid_1's l2: 0.000172813\n",
      "[2100]\ttraining's l2: 0.00017117\tvalid_1's l2: 0.000172655\n",
      "[2105]\ttraining's l2: 0.000171015\tvalid_1's l2: 0.0001725\n",
      "[2110]\ttraining's l2: 0.000170861\tvalid_1's l2: 0.000172346\n",
      "[2115]\ttraining's l2: 0.000170729\tvalid_1's l2: 0.000172212\n",
      "[2120]\ttraining's l2: 0.000170579\tvalid_1's l2: 0.000172061\n",
      "[2125]\ttraining's l2: 0.00017042\tvalid_1's l2: 0.000171902\n",
      "[2130]\ttraining's l2: 0.000170256\tvalid_1's l2: 0.00017174\n",
      "[2135]\ttraining's l2: 0.000170091\tvalid_1's l2: 0.000171574\n",
      "[2140]\ttraining's l2: 0.000169936\tvalid_1's l2: 0.000171418\n",
      "[2145]\ttraining's l2: 0.000169773\tvalid_1's l2: 0.000171255\n",
      "[2150]\ttraining's l2: 0.000169613\tvalid_1's l2: 0.000171093\n",
      "[2155]\ttraining's l2: 0.000169472\tvalid_1's l2: 0.00017095\n",
      "[2160]\ttraining's l2: 0.000169329\tvalid_1's l2: 0.000170806\n",
      "[2165]\ttraining's l2: 0.00016918\tvalid_1's l2: 0.000170657\n",
      "[2170]\ttraining's l2: 0.000169052\tvalid_1's l2: 0.000170529\n",
      "[2175]\ttraining's l2: 0.000168936\tvalid_1's l2: 0.000170412\n",
      "[2180]\ttraining's l2: 0.000168774\tvalid_1's l2: 0.000170249\n",
      "[2185]\ttraining's l2: 0.000168638\tvalid_1's l2: 0.000170112\n",
      "[2190]\ttraining's l2: 0.000168509\tvalid_1's l2: 0.000169981\n",
      "[2195]\ttraining's l2: 0.000168351\tvalid_1's l2: 0.00016982\n",
      "[2200]\ttraining's l2: 0.000168203\tvalid_1's l2: 0.000169673\n",
      "[2205]\ttraining's l2: 0.000168087\tvalid_1's l2: 0.000169555\n",
      "[2210]\ttraining's l2: 0.000167953\tvalid_1's l2: 0.000169423\n",
      "[2215]\ttraining's l2: 0.000167813\tvalid_1's l2: 0.000169282\n",
      "[2220]\ttraining's l2: 0.000167683\tvalid_1's l2: 0.000169155\n",
      "[2225]\ttraining's l2: 0.000167545\tvalid_1's l2: 0.000169015\n",
      "[2230]\ttraining's l2: 0.000167386\tvalid_1's l2: 0.000168851\n",
      "[2235]\ttraining's l2: 0.000167249\tvalid_1's l2: 0.000168714\n",
      "[2240]\ttraining's l2: 0.000167102\tvalid_1's l2: 0.000168567\n",
      "[2245]\ttraining's l2: 0.000166948\tvalid_1's l2: 0.000168411\n",
      "[2250]\ttraining's l2: 0.000166831\tvalid_1's l2: 0.000168294\n",
      "[2255]\ttraining's l2: 0.000166674\tvalid_1's l2: 0.000168139\n",
      "[2260]\ttraining's l2: 0.000166561\tvalid_1's l2: 0.000168023\n",
      "[2265]\ttraining's l2: 0.000166409\tvalid_1's l2: 0.000167873\n",
      "[2270]\ttraining's l2: 0.000166252\tvalid_1's l2: 0.000167713\n",
      "[2275]\ttraining's l2: 0.000166103\tvalid_1's l2: 0.000167564\n",
      "[2280]\ttraining's l2: 0.000165982\tvalid_1's l2: 0.000167443\n",
      "[2285]\ttraining's l2: 0.000165864\tvalid_1's l2: 0.000167324\n",
      "[2290]\ttraining's l2: 0.000165742\tvalid_1's l2: 0.000167203\n",
      "[2295]\ttraining's l2: 0.000165595\tvalid_1's l2: 0.000167055\n",
      "[2300]\ttraining's l2: 0.000165476\tvalid_1's l2: 0.000166937\n",
      "[2305]\ttraining's l2: 0.000165298\tvalid_1's l2: 0.000166758\n",
      "[2310]\ttraining's l2: 0.000165157\tvalid_1's l2: 0.000166618\n",
      "[2315]\ttraining's l2: 0.000165051\tvalid_1's l2: 0.00016651\n",
      "[2320]\ttraining's l2: 0.000164865\tvalid_1's l2: 0.000166322\n",
      "[2325]\ttraining's l2: 0.000164747\tvalid_1's l2: 0.000166203\n",
      "[2330]\ttraining's l2: 0.000164634\tvalid_1's l2: 0.000166089\n",
      "[2335]\ttraining's l2: 0.00016451\tvalid_1's l2: 0.000165965\n",
      "[2340]\ttraining's l2: 0.000164346\tvalid_1's l2: 0.000165803\n",
      "[2345]\ttraining's l2: 0.000164227\tvalid_1's l2: 0.000165684\n",
      "[2350]\ttraining's l2: 0.000164115\tvalid_1's l2: 0.00016557\n",
      "[2355]\ttraining's l2: 0.000163993\tvalid_1's l2: 0.000165446\n",
      "[2360]\ttraining's l2: 0.000163836\tvalid_1's l2: 0.000165288\n",
      "[2365]\ttraining's l2: 0.000163676\tvalid_1's l2: 0.000165129\n",
      "[2370]\ttraining's l2: 0.000163572\tvalid_1's l2: 0.000165024\n",
      "[2375]\ttraining's l2: 0.000163442\tvalid_1's l2: 0.000164894\n",
      "[2380]\ttraining's l2: 0.000163283\tvalid_1's l2: 0.000164735\n",
      "[2385]\ttraining's l2: 0.000163143\tvalid_1's l2: 0.000164594\n",
      "[2390]\ttraining's l2: 0.000163023\tvalid_1's l2: 0.000164471\n",
      "[2395]\ttraining's l2: 0.00016291\tvalid_1's l2: 0.000164359\n",
      "[2400]\ttraining's l2: 0.000162751\tvalid_1's l2: 0.000164201\n",
      "[2405]\ttraining's l2: 0.000162605\tvalid_1's l2: 0.000164053\n",
      "[2410]\ttraining's l2: 0.000162468\tvalid_1's l2: 0.000163918\n",
      "[2415]\ttraining's l2: 0.000162334\tvalid_1's l2: 0.000163783\n",
      "[2420]\ttraining's l2: 0.000162209\tvalid_1's l2: 0.000163656\n",
      "[2425]\ttraining's l2: 0.000162101\tvalid_1's l2: 0.000163547\n",
      "[2430]\ttraining's l2: 0.000161968\tvalid_1's l2: 0.000163414\n",
      "[2435]\ttraining's l2: 0.000161821\tvalid_1's l2: 0.000163265\n",
      "[2440]\ttraining's l2: 0.000161701\tvalid_1's l2: 0.000163142\n",
      "[2445]\ttraining's l2: 0.000161564\tvalid_1's l2: 0.000163003\n",
      "[2450]\ttraining's l2: 0.00016148\tvalid_1's l2: 0.000162919\n",
      "[2455]\ttraining's l2: 0.000161344\tvalid_1's l2: 0.00016278\n",
      "[2460]\ttraining's l2: 0.000161245\tvalid_1's l2: 0.000162679\n",
      "[2465]\ttraining's l2: 0.000161153\tvalid_1's l2: 0.000162587\n",
      "[2470]\ttraining's l2: 0.000161055\tvalid_1's l2: 0.000162485\n",
      "[2475]\ttraining's l2: 0.000160935\tvalid_1's l2: 0.000162366\n",
      "[2480]\ttraining's l2: 0.000160796\tvalid_1's l2: 0.000162225\n",
      "[2485]\ttraining's l2: 0.000160662\tvalid_1's l2: 0.00016209\n",
      "[2490]\ttraining's l2: 0.000160511\tvalid_1's l2: 0.000161936\n",
      "[2495]\ttraining's l2: 0.000160398\tvalid_1's l2: 0.00016182\n",
      "[2500]\ttraining's l2: 0.000160259\tvalid_1's l2: 0.000161681\n",
      "[2505]\ttraining's l2: 0.000160138\tvalid_1's l2: 0.000161559\n",
      "[2510]\ttraining's l2: 0.000160005\tvalid_1's l2: 0.000161424\n",
      "[2515]\ttraining's l2: 0.000159887\tvalid_1's l2: 0.000161306\n",
      "[2520]\ttraining's l2: 0.000159747\tvalid_1's l2: 0.000161165\n",
      "[2525]\ttraining's l2: 0.000159594\tvalid_1's l2: 0.000161009\n",
      "[2530]\ttraining's l2: 0.000159461\tvalid_1's l2: 0.000160876\n",
      "[2535]\ttraining's l2: 0.000159353\tvalid_1's l2: 0.000160767\n",
      "[2540]\ttraining's l2: 0.000159189\tvalid_1's l2: 0.000160602\n",
      "[2545]\ttraining's l2: 0.00015906\tvalid_1's l2: 0.000160473\n",
      "[2550]\ttraining's l2: 0.000158945\tvalid_1's l2: 0.000160358\n",
      "[2555]\ttraining's l2: 0.000158819\tvalid_1's l2: 0.000160231\n",
      "[2560]\ttraining's l2: 0.000158685\tvalid_1's l2: 0.000160096\n",
      "[2565]\ttraining's l2: 0.000158578\tvalid_1's l2: 0.000159989\n",
      "[2570]\ttraining's l2: 0.000158458\tvalid_1's l2: 0.000159871\n",
      "[2575]\ttraining's l2: 0.000158341\tvalid_1's l2: 0.000159752\n",
      "[2580]\ttraining's l2: 0.000158197\tvalid_1's l2: 0.000159609\n",
      "[2585]\ttraining's l2: 0.000158074\tvalid_1's l2: 0.000159486\n",
      "[2590]\ttraining's l2: 0.000157959\tvalid_1's l2: 0.000159371\n",
      "[2595]\ttraining's l2: 0.000157822\tvalid_1's l2: 0.000159234\n",
      "[2600]\ttraining's l2: 0.000157689\tvalid_1's l2: 0.0001591\n",
      "[2605]\ttraining's l2: 0.000157583\tvalid_1's l2: 0.000158993\n",
      "[2610]\ttraining's l2: 0.000157488\tvalid_1's l2: 0.000158897\n",
      "[2615]\ttraining's l2: 0.000157406\tvalid_1's l2: 0.000158817\n",
      "[2620]\ttraining's l2: 0.000157318\tvalid_1's l2: 0.000158729\n",
      "[2625]\ttraining's l2: 0.000157218\tvalid_1's l2: 0.000158628\n",
      "[2630]\ttraining's l2: 0.000157132\tvalid_1's l2: 0.000158542\n",
      "[2635]\ttraining's l2: 0.000157027\tvalid_1's l2: 0.000158437\n",
      "[2640]\ttraining's l2: 0.000156898\tvalid_1's l2: 0.000158306\n",
      "[2645]\ttraining's l2: 0.000156751\tvalid_1's l2: 0.000158159\n",
      "[2650]\ttraining's l2: 0.000156561\tvalid_1's l2: 0.000157968\n",
      "[2655]\ttraining's l2: 0.000156446\tvalid_1's l2: 0.000157853\n",
      "[2660]\ttraining's l2: 0.000156322\tvalid_1's l2: 0.000157729\n",
      "[2665]\ttraining's l2: 0.000156224\tvalid_1's l2: 0.000157633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2670]\ttraining's l2: 0.000156134\tvalid_1's l2: 0.000157544\n",
      "[2675]\ttraining's l2: 0.000156006\tvalid_1's l2: 0.000157414\n",
      "[2680]\ttraining's l2: 0.000155874\tvalid_1's l2: 0.000157281\n",
      "[2685]\ttraining's l2: 0.00015576\tvalid_1's l2: 0.000157168\n",
      "[2690]\ttraining's l2: 0.000155633\tvalid_1's l2: 0.000157041\n",
      "[2695]\ttraining's l2: 0.000155528\tvalid_1's l2: 0.000156935\n",
      "[2700]\ttraining's l2: 0.000155396\tvalid_1's l2: 0.000156804\n",
      "[2705]\ttraining's l2: 0.000155249\tvalid_1's l2: 0.000156659\n",
      "[2710]\ttraining's l2: 0.000155139\tvalid_1's l2: 0.000156549\n",
      "[2715]\ttraining's l2: 0.000155018\tvalid_1's l2: 0.000156421\n",
      "[2720]\ttraining's l2: 0.00015487\tvalid_1's l2: 0.000156269\n",
      "[2725]\ttraining's l2: 0.000154772\tvalid_1's l2: 0.000156171\n",
      "[2730]\ttraining's l2: 0.000154674\tvalid_1's l2: 0.000156072\n",
      "[2735]\ttraining's l2: 0.000154579\tvalid_1's l2: 0.00015598\n",
      "[2740]\ttraining's l2: 0.000154452\tvalid_1's l2: 0.000155853\n",
      "[2745]\ttraining's l2: 0.000154346\tvalid_1's l2: 0.000155748\n",
      "[2750]\ttraining's l2: 0.000154258\tvalid_1's l2: 0.000155658\n",
      "[2755]\ttraining's l2: 0.000154158\tvalid_1's l2: 0.000155558\n",
      "[2760]\ttraining's l2: 0.000154028\tvalid_1's l2: 0.00015543\n",
      "[2765]\ttraining's l2: 0.000153891\tvalid_1's l2: 0.000155292\n",
      "[2770]\ttraining's l2: 0.000153759\tvalid_1's l2: 0.000155161\n",
      "[2775]\ttraining's l2: 0.000153637\tvalid_1's l2: 0.000155039\n",
      "[2780]\ttraining's l2: 0.000153553\tvalid_1's l2: 0.000154954\n",
      "[2785]\ttraining's l2: 0.000153456\tvalid_1's l2: 0.000154856\n",
      "[2790]\ttraining's l2: 0.00015333\tvalid_1's l2: 0.000154727\n",
      "[2795]\ttraining's l2: 0.000153224\tvalid_1's l2: 0.00015462\n",
      "[2800]\ttraining's l2: 0.000153138\tvalid_1's l2: 0.000154532\n",
      "[2805]\ttraining's l2: 0.000153031\tvalid_1's l2: 0.000154424\n",
      "[2810]\ttraining's l2: 0.00015292\tvalid_1's l2: 0.000154316\n",
      "[2815]\ttraining's l2: 0.000152808\tvalid_1's l2: 0.000154203\n",
      "[2820]\ttraining's l2: 0.000152662\tvalid_1's l2: 0.000154058\n",
      "[2825]\ttraining's l2: 0.000152554\tvalid_1's l2: 0.00015395\n",
      "[2830]\ttraining's l2: 0.000152423\tvalid_1's l2: 0.000153817\n",
      "[2835]\ttraining's l2: 0.00015232\tvalid_1's l2: 0.000153715\n",
      "[2840]\ttraining's l2: 0.000152206\tvalid_1's l2: 0.000153597\n",
      "[2845]\ttraining's l2: 0.00015211\tvalid_1's l2: 0.000153501\n",
      "[2850]\ttraining's l2: 0.000152003\tvalid_1's l2: 0.000153395\n",
      "[2855]\ttraining's l2: 0.000151892\tvalid_1's l2: 0.000153283\n",
      "[2860]\ttraining's l2: 0.000151752\tvalid_1's l2: 0.00015314\n",
      "[2865]\ttraining's l2: 0.000151642\tvalid_1's l2: 0.00015303\n",
      "[2870]\ttraining's l2: 0.000151508\tvalid_1's l2: 0.000152895\n",
      "[2875]\ttraining's l2: 0.000151393\tvalid_1's l2: 0.000152779\n",
      "[2880]\ttraining's l2: 0.000151238\tvalid_1's l2: 0.000152622\n",
      "[2885]\ttraining's l2: 0.000151126\tvalid_1's l2: 0.00015251\n",
      "[2890]\ttraining's l2: 0.000151041\tvalid_1's l2: 0.000152424\n",
      "[2895]\ttraining's l2: 0.000150967\tvalid_1's l2: 0.000152348\n",
      "[2900]\ttraining's l2: 0.000150873\tvalid_1's l2: 0.00015225\n",
      "[2905]\ttraining's l2: 0.000150801\tvalid_1's l2: 0.000152177\n",
      "[2910]\ttraining's l2: 0.000150673\tvalid_1's l2: 0.00015205\n",
      "[2915]\ttraining's l2: 0.00015053\tvalid_1's l2: 0.000151904\n",
      "[2920]\ttraining's l2: 0.000150445\tvalid_1's l2: 0.00015182\n",
      "[2925]\ttraining's l2: 0.000150339\tvalid_1's l2: 0.000151713\n",
      "[2930]\ttraining's l2: 0.000150253\tvalid_1's l2: 0.000151627\n",
      "[2935]\ttraining's l2: 0.000150129\tvalid_1's l2: 0.000151502\n",
      "[2940]\ttraining's l2: 0.000150012\tvalid_1's l2: 0.000151383\n",
      "[2945]\ttraining's l2: 0.000149898\tvalid_1's l2: 0.000151269\n",
      "[2950]\ttraining's l2: 0.000149809\tvalid_1's l2: 0.000151176\n",
      "[2955]\ttraining's l2: 0.000149709\tvalid_1's l2: 0.000151074\n",
      "[2960]\ttraining's l2: 0.000149634\tvalid_1's l2: 0.000151\n",
      "[2965]\ttraining's l2: 0.000149544\tvalid_1's l2: 0.00015091\n",
      "[2970]\ttraining's l2: 0.000149408\tvalid_1's l2: 0.000150771\n",
      "[2975]\ttraining's l2: 0.000149253\tvalid_1's l2: 0.000150615\n",
      "[2980]\ttraining's l2: 0.000149129\tvalid_1's l2: 0.000150489\n",
      "[2985]\ttraining's l2: 0.000149021\tvalid_1's l2: 0.000150382\n",
      "[2990]\ttraining's l2: 0.000148906\tvalid_1's l2: 0.000150267\n",
      "[2995]\ttraining's l2: 0.000148832\tvalid_1's l2: 0.000150194\n",
      "[3000]\ttraining's l2: 0.000148722\tvalid_1's l2: 0.000150086\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l2: 0.000148722\tvalid_1's l2: 0.000150086\n",
      "86\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[5]\ttraining's l2: 0.00146307\tvalid_1's l2: 0.00146296\n",
      "[10]\ttraining's l2: 0.00136709\tvalid_1's l2: 0.0013668\n",
      "[15]\ttraining's l2: 0.00128534\tvalid_1's l2: 0.00128484\n",
      "[20]\ttraining's l2: 0.0012054\tvalid_1's l2: 0.00120476\n",
      "[25]\ttraining's l2: 0.00113784\tvalid_1's l2: 0.00113703\n",
      "[30]\ttraining's l2: 0.00107211\tvalid_1's l2: 0.00107117\n",
      "[35]\ttraining's l2: 0.00101223\tvalid_1's l2: 0.00101118\n",
      "[40]\ttraining's l2: 0.000958314\tvalid_1's l2: 0.000957137\n",
      "[45]\ttraining's l2: 0.000909542\tvalid_1's l2: 0.000908242\n",
      "[50]\ttraining's l2: 0.000865225\tvalid_1's l2: 0.000863813\n",
      "[55]\ttraining's l2: 0.000825177\tvalid_1's l2: 0.000823653\n",
      "[60]\ttraining's l2: 0.00078873\tvalid_1's l2: 0.000787115\n",
      "[65]\ttraining's l2: 0.00075534\tvalid_1's l2: 0.00075364\n",
      "[70]\ttraining's l2: 0.000724751\tvalid_1's l2: 0.000722967\n",
      "[75]\ttraining's l2: 0.000697907\tvalid_1's l2: 0.000696068\n",
      "[80]\ttraining's l2: 0.000672772\tvalid_1's l2: 0.00067086\n",
      "[85]\ttraining's l2: 0.000651091\tvalid_1's l2: 0.000649125\n",
      "[90]\ttraining's l2: 0.000630359\tvalid_1's l2: 0.000628365\n",
      "[95]\ttraining's l2: 0.000610613\tvalid_1's l2: 0.000608564\n",
      "[100]\ttraining's l2: 0.00059247\tvalid_1's l2: 0.000590383\n",
      "[105]\ttraining's l2: 0.000575905\tvalid_1's l2: 0.000573784\n",
      "[110]\ttraining's l2: 0.000561244\tvalid_1's l2: 0.000559098\n",
      "[115]\ttraining's l2: 0.000545814\tvalid_1's l2: 0.000543656\n",
      "[120]\ttraining's l2: 0.000532697\tvalid_1's l2: 0.000530507\n",
      "[125]\ttraining's l2: 0.000520846\tvalid_1's l2: 0.000518645\n",
      "[130]\ttraining's l2: 0.000508553\tvalid_1's l2: 0.000506324\n",
      "[135]\ttraining's l2: 0.000497321\tvalid_1's l2: 0.000495067\n",
      "[140]\ttraining's l2: 0.000487325\tvalid_1's l2: 0.000485055\n",
      "[145]\ttraining's l2: 0.000477593\tvalid_1's l2: 0.000475311\n",
      "[150]\ttraining's l2: 0.000469088\tvalid_1's l2: 0.000466787\n",
      "[155]\ttraining's l2: 0.00046064\tvalid_1's l2: 0.000458338\n",
      "[160]\ttraining's l2: 0.000452668\tvalid_1's l2: 0.000450361\n",
      "[165]\ttraining's l2: 0.000445545\tvalid_1's l2: 0.0004432\n",
      "[170]\ttraining's l2: 0.0004384\tvalid_1's l2: 0.000436046\n",
      "[175]\ttraining's l2: 0.000431978\tvalid_1's l2: 0.000429617\n",
      "[180]\ttraining's l2: 0.000425915\tvalid_1's l2: 0.000423538\n",
      "[185]\ttraining's l2: 0.000420487\tvalid_1's l2: 0.000418105\n",
      "[190]\ttraining's l2: 0.000414484\tvalid_1's l2: 0.000412105\n",
      "[195]\ttraining's l2: 0.000409649\tvalid_1's l2: 0.000407278\n",
      "[200]\ttraining's l2: 0.000404736\tvalid_1's l2: 0.000402359\n",
      "[205]\ttraining's l2: 0.000399584\tvalid_1's l2: 0.000397222\n",
      "[210]\ttraining's l2: 0.000395611\tvalid_1's l2: 0.000393255\n",
      "[215]\ttraining's l2: 0.000391397\tvalid_1's l2: 0.000389044\n",
      "[220]\ttraining's l2: 0.000387417\tvalid_1's l2: 0.000385062\n",
      "[225]\ttraining's l2: 0.000383639\tvalid_1's l2: 0.000381279\n",
      "[230]\ttraining's l2: 0.000380159\tvalid_1's l2: 0.000377803\n",
      "[235]\ttraining's l2: 0.000376457\tvalid_1's l2: 0.000374103\n",
      "[240]\ttraining's l2: 0.000373142\tvalid_1's l2: 0.000370794\n",
      "[245]\ttraining's l2: 0.000369824\tvalid_1's l2: 0.000367492\n",
      "[250]\ttraining's l2: 0.000366924\tvalid_1's l2: 0.000364609\n",
      "[255]\ttraining's l2: 0.000364114\tvalid_1's l2: 0.000361803\n",
      "[260]\ttraining's l2: 0.000361169\tvalid_1's l2: 0.000358858\n",
      "[265]\ttraining's l2: 0.000358608\tvalid_1's l2: 0.000356307\n",
      "[270]\ttraining's l2: 0.000355501\tvalid_1's l2: 0.0003532\n",
      "[275]\ttraining's l2: 0.000352456\tvalid_1's l2: 0.000350158\n",
      "[280]\ttraining's l2: 0.000350078\tvalid_1's l2: 0.000347785\n",
      "[285]\ttraining's l2: 0.000347661\tvalid_1's l2: 0.000345378\n",
      "[290]\ttraining's l2: 0.000345045\tvalid_1's l2: 0.000342771\n",
      "[295]\ttraining's l2: 0.000343056\tvalid_1's l2: 0.000340802\n",
      "[300]\ttraining's l2: 0.000340715\tvalid_1's l2: 0.000338462\n",
      "[305]\ttraining's l2: 0.000338202\tvalid_1's l2: 0.000335957\n",
      "[310]\ttraining's l2: 0.000335489\tvalid_1's l2: 0.000333263\n",
      "[315]\ttraining's l2: 0.000333502\tvalid_1's l2: 0.00033128\n",
      "[320]\ttraining's l2: 0.000331503\tvalid_1's l2: 0.000329288\n",
      "[325]\ttraining's l2: 0.000329366\tvalid_1's l2: 0.000327147\n",
      "[330]\ttraining's l2: 0.000327405\tvalid_1's l2: 0.000325191\n",
      "[335]\ttraining's l2: 0.000325356\tvalid_1's l2: 0.000323145\n",
      "[340]\ttraining's l2: 0.000323504\tvalid_1's l2: 0.000321304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[345]\ttraining's l2: 0.000321672\tvalid_1's l2: 0.000319472\n",
      "[350]\ttraining's l2: 0.000319867\tvalid_1's l2: 0.000317681\n",
      "[355]\ttraining's l2: 0.000318114\tvalid_1's l2: 0.000315931\n",
      "[360]\ttraining's l2: 0.000316227\tvalid_1's l2: 0.00031404\n",
      "[365]\ttraining's l2: 0.000314412\tvalid_1's l2: 0.000312227\n",
      "[370]\ttraining's l2: 0.000312933\tvalid_1's l2: 0.000310758\n",
      "[375]\ttraining's l2: 0.000311311\tvalid_1's l2: 0.000309148\n",
      "[380]\ttraining's l2: 0.000309621\tvalid_1's l2: 0.000307474\n",
      "[385]\ttraining's l2: 0.000308002\tvalid_1's l2: 0.000305865\n",
      "[390]\ttraining's l2: 0.000306394\tvalid_1's l2: 0.000304267\n",
      "[395]\ttraining's l2: 0.000304831\tvalid_1's l2: 0.000302714\n",
      "[400]\ttraining's l2: 0.000303335\tvalid_1's l2: 0.000301239\n",
      "[405]\ttraining's l2: 0.000301907\tvalid_1's l2: 0.000299818\n",
      "[410]\ttraining's l2: 0.00030025\tvalid_1's l2: 0.000298195\n",
      "[415]\ttraining's l2: 0.000298923\tvalid_1's l2: 0.000296879\n",
      "[420]\ttraining's l2: 0.000297484\tvalid_1's l2: 0.000295459\n",
      "[425]\ttraining's l2: 0.000295999\tvalid_1's l2: 0.000293998\n",
      "[430]\ttraining's l2: 0.000294569\tvalid_1's l2: 0.000292573\n",
      "[435]\ttraining's l2: 0.000293436\tvalid_1's l2: 0.000291461\n",
      "[440]\ttraining's l2: 0.000292363\tvalid_1's l2: 0.000290397\n",
      "[445]\ttraining's l2: 0.000291185\tvalid_1's l2: 0.000289229\n",
      "[450]\ttraining's l2: 0.000290078\tvalid_1's l2: 0.000288143\n",
      "[455]\ttraining's l2: 0.000288884\tvalid_1's l2: 0.000286964\n",
      "[460]\ttraining's l2: 0.000287673\tvalid_1's l2: 0.000285772\n",
      "[465]\ttraining's l2: 0.000286416\tvalid_1's l2: 0.000284522\n",
      "[470]\ttraining's l2: 0.00028537\tvalid_1's l2: 0.000283493\n",
      "[475]\ttraining's l2: 0.000284312\tvalid_1's l2: 0.000282448\n",
      "[480]\ttraining's l2: 0.000283147\tvalid_1's l2: 0.000281292\n",
      "[485]\ttraining's l2: 0.00028225\tvalid_1's l2: 0.000280405\n",
      "[490]\ttraining's l2: 0.000281236\tvalid_1's l2: 0.000279401\n",
      "[495]\ttraining's l2: 0.00028015\tvalid_1's l2: 0.000278318\n",
      "[500]\ttraining's l2: 0.000279155\tvalid_1's l2: 0.000277338\n",
      "[505]\ttraining's l2: 0.000278224\tvalid_1's l2: 0.000276418\n",
      "[510]\ttraining's l2: 0.000277241\tvalid_1's l2: 0.000275446\n",
      "[515]\ttraining's l2: 0.000276305\tvalid_1's l2: 0.000274525\n",
      "[520]\ttraining's l2: 0.000275458\tvalid_1's l2: 0.00027369\n",
      "[525]\ttraining's l2: 0.000274657\tvalid_1's l2: 0.000272896\n",
      "[530]\ttraining's l2: 0.000273762\tvalid_1's l2: 0.000272014\n",
      "[535]\ttraining's l2: 0.000272883\tvalid_1's l2: 0.000271142\n",
      "[540]\ttraining's l2: 0.000271967\tvalid_1's l2: 0.000270228\n",
      "[545]\ttraining's l2: 0.000270949\tvalid_1's l2: 0.000269217\n",
      "[550]\ttraining's l2: 0.000270031\tvalid_1's l2: 0.000268309\n",
      "[555]\ttraining's l2: 0.000269181\tvalid_1's l2: 0.000267461\n",
      "[560]\ttraining's l2: 0.000268383\tvalid_1's l2: 0.000266677\n",
      "[565]\ttraining's l2: 0.000267583\tvalid_1's l2: 0.000265885\n",
      "[570]\ttraining's l2: 0.000266719\tvalid_1's l2: 0.000265041\n",
      "[575]\ttraining's l2: 0.000265903\tvalid_1's l2: 0.000264232\n",
      "[580]\ttraining's l2: 0.000265043\tvalid_1's l2: 0.000263385\n",
      "[585]\ttraining's l2: 0.000264237\tvalid_1's l2: 0.000262588\n",
      "[590]\ttraining's l2: 0.000263501\tvalid_1's l2: 0.000261865\n",
      "[595]\ttraining's l2: 0.00026264\tvalid_1's l2: 0.00026102\n",
      "[600]\ttraining's l2: 0.00026196\tvalid_1's l2: 0.00026035\n",
      "[605]\ttraining's l2: 0.000261227\tvalid_1's l2: 0.000259624\n",
      "[610]\ttraining's l2: 0.000260574\tvalid_1's l2: 0.000258974\n",
      "[615]\ttraining's l2: 0.000259807\tvalid_1's l2: 0.000258215\n",
      "[620]\ttraining's l2: 0.000259086\tvalid_1's l2: 0.000257508\n",
      "[625]\ttraining's l2: 0.000258355\tvalid_1's l2: 0.000256784\n",
      "[630]\ttraining's l2: 0.000257639\tvalid_1's l2: 0.000256074\n",
      "[635]\ttraining's l2: 0.000257027\tvalid_1's l2: 0.00025547\n",
      "[640]\ttraining's l2: 0.000256358\tvalid_1's l2: 0.000254814\n",
      "[645]\ttraining's l2: 0.000255659\tvalid_1's l2: 0.000254119\n",
      "[650]\ttraining's l2: 0.000254943\tvalid_1's l2: 0.00025341\n",
      "[655]\ttraining's l2: 0.000254351\tvalid_1's l2: 0.00025282\n",
      "[660]\ttraining's l2: 0.000253704\tvalid_1's l2: 0.000252182\n",
      "[665]\ttraining's l2: 0.000253022\tvalid_1's l2: 0.000251504\n",
      "[670]\ttraining's l2: 0.0002524\tvalid_1's l2: 0.000250889\n",
      "[675]\ttraining's l2: 0.000251807\tvalid_1's l2: 0.000250301\n",
      "[680]\ttraining's l2: 0.000251249\tvalid_1's l2: 0.000249748\n",
      "[685]\ttraining's l2: 0.00025061\tvalid_1's l2: 0.000249117\n",
      "[690]\ttraining's l2: 0.000249962\tvalid_1's l2: 0.000248475\n",
      "[695]\ttraining's l2: 0.000249375\tvalid_1's l2: 0.000247894\n",
      "[700]\ttraining's l2: 0.000248829\tvalid_1's l2: 0.000247356\n",
      "[705]\ttraining's l2: 0.000248275\tvalid_1's l2: 0.000246813\n",
      "[710]\ttraining's l2: 0.000247597\tvalid_1's l2: 0.000246139\n",
      "[715]\ttraining's l2: 0.000247096\tvalid_1's l2: 0.000245643\n",
      "[720]\ttraining's l2: 0.000246492\tvalid_1's l2: 0.000245051\n",
      "[725]\ttraining's l2: 0.000245884\tvalid_1's l2: 0.000244451\n",
      "[730]\ttraining's l2: 0.000245354\tvalid_1's l2: 0.000243933\n",
      "[735]\ttraining's l2: 0.000244769\tvalid_1's l2: 0.000243357\n",
      "[740]\ttraining's l2: 0.000244153\tvalid_1's l2: 0.000242742\n",
      "[745]\ttraining's l2: 0.000243635\tvalid_1's l2: 0.000242234\n",
      "[750]\ttraining's l2: 0.000243189\tvalid_1's l2: 0.000241793\n",
      "[755]\ttraining's l2: 0.000242602\tvalid_1's l2: 0.000241215\n",
      "[760]\ttraining's l2: 0.000242001\tvalid_1's l2: 0.00024063\n",
      "[765]\ttraining's l2: 0.000241406\tvalid_1's l2: 0.000240042\n",
      "[770]\ttraining's l2: 0.000240961\tvalid_1's l2: 0.000239602\n",
      "[775]\ttraining's l2: 0.000240368\tvalid_1's l2: 0.000239018\n",
      "[780]\ttraining's l2: 0.000239881\tvalid_1's l2: 0.000238534\n",
      "[785]\ttraining's l2: 0.000239359\tvalid_1's l2: 0.00023802\n",
      "[790]\ttraining's l2: 0.00023893\tvalid_1's l2: 0.000237595\n",
      "[795]\ttraining's l2: 0.00023841\tvalid_1's l2: 0.000237081\n",
      "[800]\ttraining's l2: 0.000237975\tvalid_1's l2: 0.00023665\n",
      "[805]\ttraining's l2: 0.000237487\tvalid_1's l2: 0.000236171\n",
      "[810]\ttraining's l2: 0.000236943\tvalid_1's l2: 0.000235626\n",
      "[815]\ttraining's l2: 0.000236523\tvalid_1's l2: 0.000235216\n",
      "[820]\ttraining's l2: 0.000236096\tvalid_1's l2: 0.000234796\n",
      "[825]\ttraining's l2: 0.000235658\tvalid_1's l2: 0.000234363\n",
      "[830]\ttraining's l2: 0.000235113\tvalid_1's l2: 0.00023383\n",
      "[835]\ttraining's l2: 0.000234661\tvalid_1's l2: 0.000233383\n",
      "[840]\ttraining's l2: 0.00023419\tvalid_1's l2: 0.000232918\n",
      "[845]\ttraining's l2: 0.000233721\tvalid_1's l2: 0.000232458\n",
      "[850]\ttraining's l2: 0.000233287\tvalid_1's l2: 0.000232034\n",
      "[855]\ttraining's l2: 0.00023279\tvalid_1's l2: 0.000231548\n",
      "[860]\ttraining's l2: 0.000232285\tvalid_1's l2: 0.000231047\n",
      "[865]\ttraining's l2: 0.000231866\tvalid_1's l2: 0.000230633\n",
      "[870]\ttraining's l2: 0.000231445\tvalid_1's l2: 0.00023022\n",
      "[875]\ttraining's l2: 0.000231015\tvalid_1's l2: 0.000229801\n",
      "[880]\ttraining's l2: 0.000230591\tvalid_1's l2: 0.000229383\n",
      "[885]\ttraining's l2: 0.000230134\tvalid_1's l2: 0.000228932\n",
      "[890]\ttraining's l2: 0.000229682\tvalid_1's l2: 0.000228483\n",
      "[895]\ttraining's l2: 0.000229211\tvalid_1's l2: 0.000228022\n",
      "[900]\ttraining's l2: 0.000228871\tvalid_1's l2: 0.000227683\n",
      "[905]\ttraining's l2: 0.000228466\tvalid_1's l2: 0.000227288\n",
      "[910]\ttraining's l2: 0.000228088\tvalid_1's l2: 0.000226916\n",
      "[915]\ttraining's l2: 0.000227697\tvalid_1's l2: 0.000226528\n",
      "[920]\ttraining's l2: 0.0002273\tvalid_1's l2: 0.00022614\n",
      "[925]\ttraining's l2: 0.000226912\tvalid_1's l2: 0.000225764\n",
      "[930]\ttraining's l2: 0.000226538\tvalid_1's l2: 0.000225393\n",
      "[935]\ttraining's l2: 0.000226139\tvalid_1's l2: 0.000225001\n",
      "[940]\ttraining's l2: 0.000225782\tvalid_1's l2: 0.00022465\n",
      "[945]\ttraining's l2: 0.000225383\tvalid_1's l2: 0.000224257\n",
      "[950]\ttraining's l2: 0.000225011\tvalid_1's l2: 0.000223888\n",
      "[955]\ttraining's l2: 0.000224623\tvalid_1's l2: 0.000223501\n",
      "[960]\ttraining's l2: 0.000224292\tvalid_1's l2: 0.000223173\n",
      "[965]\ttraining's l2: 0.000223909\tvalid_1's l2: 0.000222794\n",
      "[970]\ttraining's l2: 0.00022354\tvalid_1's l2: 0.00022243\n",
      "[975]\ttraining's l2: 0.000223083\tvalid_1's l2: 0.000221982\n",
      "[980]\ttraining's l2: 0.00022272\tvalid_1's l2: 0.000221623\n",
      "[985]\ttraining's l2: 0.000222413\tvalid_1's l2: 0.000221325\n",
      "[990]\ttraining's l2: 0.000222066\tvalid_1's l2: 0.000220983\n",
      "[995]\ttraining's l2: 0.000221707\tvalid_1's l2: 0.000220621\n",
      "[1000]\ttraining's l2: 0.000221314\tvalid_1's l2: 0.00022023\n",
      "[1005]\ttraining's l2: 0.000220939\tvalid_1's l2: 0.000219858\n",
      "[1010]\ttraining's l2: 0.000220606\tvalid_1's l2: 0.000219531\n",
      "[1015]\ttraining's l2: 0.000220129\tvalid_1's l2: 0.000219058\n",
      "[1020]\ttraining's l2: 0.000219783\tvalid_1's l2: 0.000218719\n",
      "[1025]\ttraining's l2: 0.000219396\tvalid_1's l2: 0.000218336\n",
      "[1030]\ttraining's l2: 0.000219073\tvalid_1's l2: 0.000218017\n",
      "[1035]\ttraining's l2: 0.00021879\tvalid_1's l2: 0.000217737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1040]\ttraining's l2: 0.0002185\tvalid_1's l2: 0.000217448\n",
      "[1045]\ttraining's l2: 0.000218122\tvalid_1's l2: 0.000217073\n",
      "[1050]\ttraining's l2: 0.000217742\tvalid_1's l2: 0.000216694\n",
      "[1055]\ttraining's l2: 0.00021742\tvalid_1's l2: 0.000216378\n",
      "[1060]\ttraining's l2: 0.000217035\tvalid_1's l2: 0.000216002\n",
      "[1065]\ttraining's l2: 0.000216626\tvalid_1's l2: 0.000215598\n",
      "[1070]\ttraining's l2: 0.00021627\tvalid_1's l2: 0.000215243\n",
      "[1075]\ttraining's l2: 0.000215928\tvalid_1's l2: 0.000214912\n",
      "[1080]\ttraining's l2: 0.000215554\tvalid_1's l2: 0.000214536\n",
      "[1085]\ttraining's l2: 0.000215269\tvalid_1's l2: 0.000214255\n",
      "[1090]\ttraining's l2: 0.000214978\tvalid_1's l2: 0.000213969\n",
      "[1095]\ttraining's l2: 0.000214587\tvalid_1's l2: 0.000213583\n",
      "[1100]\ttraining's l2: 0.000214304\tvalid_1's l2: 0.000213303\n",
      "[1105]\ttraining's l2: 0.000213951\tvalid_1's l2: 0.000212955\n",
      "[1110]\ttraining's l2: 0.000213572\tvalid_1's l2: 0.000212573\n",
      "[1115]\ttraining's l2: 0.000213223\tvalid_1's l2: 0.000212225\n",
      "[1120]\ttraining's l2: 0.00021285\tvalid_1's l2: 0.000211854\n",
      "[1125]\ttraining's l2: 0.000212576\tvalid_1's l2: 0.000211581\n",
      "[1130]\ttraining's l2: 0.000212296\tvalid_1's l2: 0.000211302\n",
      "[1135]\ttraining's l2: 0.000211968\tvalid_1's l2: 0.000210978\n",
      "[1140]\ttraining's l2: 0.000211689\tvalid_1's l2: 0.000210708\n",
      "[1145]\ttraining's l2: 0.000211326\tvalid_1's l2: 0.000210347\n",
      "[1150]\ttraining's l2: 0.000211024\tvalid_1's l2: 0.000210045\n",
      "[1155]\ttraining's l2: 0.000210662\tvalid_1's l2: 0.000209687\n",
      "[1160]\ttraining's l2: 0.000210342\tvalid_1's l2: 0.000209373\n",
      "[1165]\ttraining's l2: 0.000209957\tvalid_1's l2: 0.000208997\n",
      "[1170]\ttraining's l2: 0.000209671\tvalid_1's l2: 0.000208718\n",
      "[1175]\ttraining's l2: 0.000209331\tvalid_1's l2: 0.000208382\n",
      "[1180]\ttraining's l2: 0.000209013\tvalid_1's l2: 0.000208066\n",
      "[1185]\ttraining's l2: 0.000208734\tvalid_1's l2: 0.000207792\n",
      "[1190]\ttraining's l2: 0.000208468\tvalid_1's l2: 0.000207527\n",
      "[1195]\ttraining's l2: 0.00020815\tvalid_1's l2: 0.00020721\n",
      "[1200]\ttraining's l2: 0.000207861\tvalid_1's l2: 0.000206926\n",
      "[1205]\ttraining's l2: 0.00020757\tvalid_1's l2: 0.000206637\n",
      "[1210]\ttraining's l2: 0.00020732\tvalid_1's l2: 0.000206393\n",
      "[1215]\ttraining's l2: 0.000206963\tvalid_1's l2: 0.000206038\n",
      "[1220]\ttraining's l2: 0.000206614\tvalid_1's l2: 0.000205687\n",
      "[1225]\ttraining's l2: 0.000206316\tvalid_1's l2: 0.000205397\n",
      "[1230]\ttraining's l2: 0.000206031\tvalid_1's l2: 0.000205119\n",
      "[1235]\ttraining's l2: 0.000205769\tvalid_1's l2: 0.000204863\n",
      "[1240]\ttraining's l2: 0.000205459\tvalid_1's l2: 0.00020456\n",
      "[1245]\ttraining's l2: 0.000205172\tvalid_1's l2: 0.000204279\n",
      "[1250]\ttraining's l2: 0.000204882\tvalid_1's l2: 0.000203991\n",
      "[1255]\ttraining's l2: 0.000204554\tvalid_1's l2: 0.000203663\n",
      "[1260]\ttraining's l2: 0.000204193\tvalid_1's l2: 0.000203305\n",
      "[1265]\ttraining's l2: 0.000203971\tvalid_1's l2: 0.000203087\n",
      "[1270]\ttraining's l2: 0.000203669\tvalid_1's l2: 0.00020279\n",
      "[1275]\ttraining's l2: 0.000203381\tvalid_1's l2: 0.000202507\n",
      "[1280]\ttraining's l2: 0.00020302\tvalid_1's l2: 0.000202147\n",
      "[1285]\ttraining's l2: 0.000202755\tvalid_1's l2: 0.000201882\n",
      "[1290]\ttraining's l2: 0.00020248\tvalid_1's l2: 0.000201607\n",
      "[1295]\ttraining's l2: 0.000202223\tvalid_1's l2: 0.000201354\n",
      "[1300]\ttraining's l2: 0.000201959\tvalid_1's l2: 0.000201096\n",
      "[1305]\ttraining's l2: 0.000201666\tvalid_1's l2: 0.000200803\n",
      "[1310]\ttraining's l2: 0.000201391\tvalid_1's l2: 0.00020053\n",
      "[1315]\ttraining's l2: 0.00020115\tvalid_1's l2: 0.000200294\n",
      "[1320]\ttraining's l2: 0.000200927\tvalid_1's l2: 0.000200076\n",
      "[1325]\ttraining's l2: 0.000200667\tvalid_1's l2: 0.000199822\n",
      "[1330]\ttraining's l2: 0.000200454\tvalid_1's l2: 0.000199614\n",
      "[1335]\ttraining's l2: 0.000200107\tvalid_1's l2: 0.000199273\n",
      "[1340]\ttraining's l2: 0.000199786\tvalid_1's l2: 0.000198949\n",
      "[1345]\ttraining's l2: 0.000199551\tvalid_1's l2: 0.000198717\n",
      "[1350]\ttraining's l2: 0.000199311\tvalid_1's l2: 0.000198481\n",
      "[1355]\ttraining's l2: 0.000199014\tvalid_1's l2: 0.000198185\n",
      "[1360]\ttraining's l2: 0.000198716\tvalid_1's l2: 0.000197894\n",
      "[1365]\ttraining's l2: 0.000198442\tvalid_1's l2: 0.000197623\n",
      "[1370]\ttraining's l2: 0.000198143\tvalid_1's l2: 0.000197331\n",
      "[1375]\ttraining's l2: 0.000197836\tvalid_1's l2: 0.000197027\n",
      "[1380]\ttraining's l2: 0.000197576\tvalid_1's l2: 0.000196767\n",
      "[1385]\ttraining's l2: 0.000197358\tvalid_1's l2: 0.000196554\n",
      "[1390]\ttraining's l2: 0.000197137\tvalid_1's l2: 0.000196337\n",
      "[1395]\ttraining's l2: 0.000196899\tvalid_1's l2: 0.000196104\n",
      "[1400]\ttraining's l2: 0.000196614\tvalid_1's l2: 0.000195819\n",
      "[1405]\ttraining's l2: 0.000196337\tvalid_1's l2: 0.000195542\n",
      "[1410]\ttraining's l2: 0.000196082\tvalid_1's l2: 0.000195291\n",
      "[1415]\ttraining's l2: 0.000195831\tvalid_1's l2: 0.000195043\n",
      "[1420]\ttraining's l2: 0.000195612\tvalid_1's l2: 0.000194824\n",
      "[1425]\ttraining's l2: 0.000195438\tvalid_1's l2: 0.000194648\n",
      "[1430]\ttraining's l2: 0.000195123\tvalid_1's l2: 0.000194335\n",
      "[1435]\ttraining's l2: 0.000194866\tvalid_1's l2: 0.000194081\n",
      "[1440]\ttraining's l2: 0.000194583\tvalid_1's l2: 0.000193804\n",
      "[1445]\ttraining's l2: 0.000194368\tvalid_1's l2: 0.000193589\n",
      "[1450]\ttraining's l2: 0.000194105\tvalid_1's l2: 0.000193328\n",
      "[1455]\ttraining's l2: 0.000193871\tvalid_1's l2: 0.000193095\n",
      "[1460]\ttraining's l2: 0.000193669\tvalid_1's l2: 0.000192898\n",
      "[1465]\ttraining's l2: 0.000193438\tvalid_1's l2: 0.000192662\n",
      "[1470]\ttraining's l2: 0.000193254\tvalid_1's l2: 0.000192477\n",
      "[1475]\ttraining's l2: 0.000193061\tvalid_1's l2: 0.000192289\n",
      "[1480]\ttraining's l2: 0.000192852\tvalid_1's l2: 0.000192082\n",
      "[1485]\ttraining's l2: 0.000192572\tvalid_1's l2: 0.000191801\n",
      "[1490]\ttraining's l2: 0.00019238\tvalid_1's l2: 0.000191608\n",
      "[1495]\ttraining's l2: 0.000192161\tvalid_1's l2: 0.000191395\n",
      "[1500]\ttraining's l2: 0.000191935\tvalid_1's l2: 0.000191172\n",
      "[1505]\ttraining's l2: 0.000191694\tvalid_1's l2: 0.00019093\n",
      "[1510]\ttraining's l2: 0.000191486\tvalid_1's l2: 0.000190723\n",
      "[1515]\ttraining's l2: 0.0001912\tvalid_1's l2: 0.000190442\n",
      "[1520]\ttraining's l2: 0.000190969\tvalid_1's l2: 0.000190211\n",
      "[1525]\ttraining's l2: 0.000190717\tvalid_1's l2: 0.000189958\n",
      "[1530]\ttraining's l2: 0.000190498\tvalid_1's l2: 0.000189742\n",
      "[1535]\ttraining's l2: 0.000190274\tvalid_1's l2: 0.00018952\n",
      "[1540]\ttraining's l2: 0.000189996\tvalid_1's l2: 0.000189246\n",
      "[1545]\ttraining's l2: 0.000189733\tvalid_1's l2: 0.000188985\n",
      "[1550]\ttraining's l2: 0.000189552\tvalid_1's l2: 0.000188807\n",
      "[1555]\ttraining's l2: 0.000189296\tvalid_1's l2: 0.000188554\n",
      "[1560]\ttraining's l2: 0.000189098\tvalid_1's l2: 0.000188358\n",
      "[1565]\ttraining's l2: 0.000188901\tvalid_1's l2: 0.000188165\n",
      "[1570]\ttraining's l2: 0.000188663\tvalid_1's l2: 0.000187931\n",
      "[1575]\ttraining's l2: 0.000188475\tvalid_1's l2: 0.000187745\n",
      "[1580]\ttraining's l2: 0.000188298\tvalid_1's l2: 0.000187571\n",
      "[1585]\ttraining's l2: 0.000188112\tvalid_1's l2: 0.000187385\n",
      "[1590]\ttraining's l2: 0.000187948\tvalid_1's l2: 0.000187227\n",
      "[1595]\ttraining's l2: 0.000187721\tvalid_1's l2: 0.000187003\n",
      "[1600]\ttraining's l2: 0.000187547\tvalid_1's l2: 0.00018683\n",
      "[1605]\ttraining's l2: 0.000187292\tvalid_1's l2: 0.000186582\n",
      "[1610]\ttraining's l2: 0.000187087\tvalid_1's l2: 0.00018638\n",
      "[1615]\ttraining's l2: 0.000186897\tvalid_1's l2: 0.000186188\n",
      "[1620]\ttraining's l2: 0.000186642\tvalid_1's l2: 0.000185936\n",
      "[1625]\ttraining's l2: 0.00018643\tvalid_1's l2: 0.000185725\n",
      "[1630]\ttraining's l2: 0.000186196\tvalid_1's l2: 0.00018549\n",
      "[1635]\ttraining's l2: 0.000186015\tvalid_1's l2: 0.000185308\n",
      "[1640]\ttraining's l2: 0.000185812\tvalid_1's l2: 0.000185106\n",
      "[1645]\ttraining's l2: 0.00018561\tvalid_1's l2: 0.000184903\n",
      "[1650]\ttraining's l2: 0.0001854\tvalid_1's l2: 0.000184693\n",
      "[1655]\ttraining's l2: 0.000185182\tvalid_1's l2: 0.000184475\n",
      "[1660]\ttraining's l2: 0.000185006\tvalid_1's l2: 0.000184301\n",
      "[1665]\ttraining's l2: 0.000184804\tvalid_1's l2: 0.000184106\n",
      "[1670]\ttraining's l2: 0.000184579\tvalid_1's l2: 0.000183885\n",
      "[1675]\ttraining's l2: 0.000184321\tvalid_1's l2: 0.000183628\n",
      "[1680]\ttraining's l2: 0.000184137\tvalid_1's l2: 0.000183445\n",
      "[1685]\ttraining's l2: 0.000183945\tvalid_1's l2: 0.000183259\n",
      "[1690]\ttraining's l2: 0.000183734\tvalid_1's l2: 0.000183052\n",
      "[1695]\ttraining's l2: 0.000183555\tvalid_1's l2: 0.000182874\n",
      "[1700]\ttraining's l2: 0.00018332\tvalid_1's l2: 0.000182643\n",
      "[1705]\ttraining's l2: 0.000183171\tvalid_1's l2: 0.000182499\n",
      "[1710]\ttraining's l2: 0.000183004\tvalid_1's l2: 0.000182328\n",
      "[1715]\ttraining's l2: 0.000182809\tvalid_1's l2: 0.000182135\n",
      "[1720]\ttraining's l2: 0.000182633\tvalid_1's l2: 0.00018196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1725]\ttraining's l2: 0.000182469\tvalid_1's l2: 0.000181801\n",
      "[1730]\ttraining's l2: 0.000182223\tvalid_1's l2: 0.000181553\n",
      "[1735]\ttraining's l2: 0.000182031\tvalid_1's l2: 0.000181362\n",
      "[1740]\ttraining's l2: 0.000181803\tvalid_1's l2: 0.000181134\n",
      "[1745]\ttraining's l2: 0.000181597\tvalid_1's l2: 0.000180934\n",
      "[1750]\ttraining's l2: 0.000181434\tvalid_1's l2: 0.000180777\n",
      "[1755]\ttraining's l2: 0.000181223\tvalid_1's l2: 0.000180563\n",
      "[1760]\ttraining's l2: 0.000181028\tvalid_1's l2: 0.000180374\n",
      "[1765]\ttraining's l2: 0.000180849\tvalid_1's l2: 0.000180196\n",
      "[1770]\ttraining's l2: 0.000180674\tvalid_1's l2: 0.000180021\n",
      "[1775]\ttraining's l2: 0.000180509\tvalid_1's l2: 0.000179854\n",
      "[1780]\ttraining's l2: 0.000180294\tvalid_1's l2: 0.000179641\n",
      "[1785]\ttraining's l2: 0.000180098\tvalid_1's l2: 0.000179447\n",
      "[1790]\ttraining's l2: 0.000179918\tvalid_1's l2: 0.000179271\n",
      "[1795]\ttraining's l2: 0.000179745\tvalid_1's l2: 0.000179099\n",
      "[1800]\ttraining's l2: 0.000179521\tvalid_1's l2: 0.000178874\n",
      "[1805]\ttraining's l2: 0.000179299\tvalid_1's l2: 0.00017865\n",
      "[1810]\ttraining's l2: 0.000179155\tvalid_1's l2: 0.000178506\n",
      "[1815]\ttraining's l2: 0.000178965\tvalid_1's l2: 0.000178319\n",
      "[1820]\ttraining's l2: 0.00017876\tvalid_1's l2: 0.000178112\n",
      "[1825]\ttraining's l2: 0.00017861\tvalid_1's l2: 0.000177965\n",
      "[1830]\ttraining's l2: 0.000178443\tvalid_1's l2: 0.000177805\n",
      "[1835]\ttraining's l2: 0.000178283\tvalid_1's l2: 0.000177646\n",
      "[1840]\ttraining's l2: 0.000178097\tvalid_1's l2: 0.000177464\n",
      "[1845]\ttraining's l2: 0.000177935\tvalid_1's l2: 0.000177304\n",
      "[1850]\ttraining's l2: 0.000177761\tvalid_1's l2: 0.000177134\n",
      "[1855]\ttraining's l2: 0.000177599\tvalid_1's l2: 0.000176972\n",
      "[1860]\ttraining's l2: 0.000177445\tvalid_1's l2: 0.000176817\n",
      "[1865]\ttraining's l2: 0.000177288\tvalid_1's l2: 0.000176661\n",
      "[1870]\ttraining's l2: 0.000177141\tvalid_1's l2: 0.000176516\n",
      "[1875]\ttraining's l2: 0.000176976\tvalid_1's l2: 0.000176352\n",
      "[1880]\ttraining's l2: 0.000176719\tvalid_1's l2: 0.000176099\n",
      "[1885]\ttraining's l2: 0.00017655\tvalid_1's l2: 0.000175937\n",
      "[1890]\ttraining's l2: 0.000176384\tvalid_1's l2: 0.000175776\n",
      "[1895]\ttraining's l2: 0.000176241\tvalid_1's l2: 0.000175634\n",
      "[1900]\ttraining's l2: 0.000176045\tvalid_1's l2: 0.000175443\n",
      "[1905]\ttraining's l2: 0.000175829\tvalid_1's l2: 0.000175225\n",
      "[1910]\ttraining's l2: 0.000175619\tvalid_1's l2: 0.000175015\n",
      "[1915]\ttraining's l2: 0.000175432\tvalid_1's l2: 0.000174835\n",
      "[1920]\ttraining's l2: 0.000175255\tvalid_1's l2: 0.000174659\n",
      "[1925]\ttraining's l2: 0.000175104\tvalid_1's l2: 0.00017451\n",
      "[1930]\ttraining's l2: 0.000174902\tvalid_1's l2: 0.000174306\n",
      "[1935]\ttraining's l2: 0.000174715\tvalid_1's l2: 0.000174118\n",
      "[1940]\ttraining's l2: 0.000174514\tvalid_1's l2: 0.000173921\n",
      "[1945]\ttraining's l2: 0.000174355\tvalid_1's l2: 0.000173765\n",
      "[1950]\ttraining's l2: 0.000174213\tvalid_1's l2: 0.000173628\n",
      "[1955]\ttraining's l2: 0.000174019\tvalid_1's l2: 0.00017344\n",
      "[1960]\ttraining's l2: 0.000173897\tvalid_1's l2: 0.000173316\n",
      "[1965]\ttraining's l2: 0.000173682\tvalid_1's l2: 0.000173106\n",
      "[1970]\ttraining's l2: 0.000173508\tvalid_1's l2: 0.000172931\n",
      "[1975]\ttraining's l2: 0.000173335\tvalid_1's l2: 0.000172761\n",
      "[1980]\ttraining's l2: 0.000173194\tvalid_1's l2: 0.00017262\n",
      "[1985]\ttraining's l2: 0.00017304\tvalid_1's l2: 0.000172472\n",
      "[1990]\ttraining's l2: 0.000172896\tvalid_1's l2: 0.000172328\n",
      "[1995]\ttraining's l2: 0.000172755\tvalid_1's l2: 0.000172191\n",
      "[2000]\ttraining's l2: 0.00017258\tvalid_1's l2: 0.00017202\n",
      "[2005]\ttraining's l2: 0.000172427\tvalid_1's l2: 0.000171871\n",
      "[2010]\ttraining's l2: 0.000172297\tvalid_1's l2: 0.000171744\n",
      "[2015]\ttraining's l2: 0.000172148\tvalid_1's l2: 0.000171595\n",
      "[2020]\ttraining's l2: 0.000171985\tvalid_1's l2: 0.00017143\n",
      "[2025]\ttraining's l2: 0.000171783\tvalid_1's l2: 0.000171231\n",
      "[2030]\ttraining's l2: 0.000171625\tvalid_1's l2: 0.000171073\n",
      "[2035]\ttraining's l2: 0.000171466\tvalid_1's l2: 0.000170914\n",
      "[2040]\ttraining's l2: 0.000171299\tvalid_1's l2: 0.000170753\n",
      "[2045]\ttraining's l2: 0.000171173\tvalid_1's l2: 0.000170628\n",
      "[2050]\ttraining's l2: 0.000171033\tvalid_1's l2: 0.000170491\n",
      "[2055]\ttraining's l2: 0.000170881\tvalid_1's l2: 0.000170341\n",
      "[2060]\ttraining's l2: 0.000170745\tvalid_1's l2: 0.000170206\n",
      "[2065]\ttraining's l2: 0.000170604\tvalid_1's l2: 0.000170067\n",
      "[2070]\ttraining's l2: 0.00017045\tvalid_1's l2: 0.000169913\n",
      "[2075]\ttraining's l2: 0.00017028\tvalid_1's l2: 0.000169744\n",
      "[2080]\ttraining's l2: 0.000170185\tvalid_1's l2: 0.000169653\n",
      "[2085]\ttraining's l2: 0.000170021\tvalid_1's l2: 0.000169492\n",
      "[2090]\ttraining's l2: 0.000169879\tvalid_1's l2: 0.000169353\n",
      "[2095]\ttraining's l2: 0.000169755\tvalid_1's l2: 0.000169231\n",
      "[2100]\ttraining's l2: 0.000169611\tvalid_1's l2: 0.000169089\n",
      "[2105]\ttraining's l2: 0.000169459\tvalid_1's l2: 0.000168945\n",
      "[2110]\ttraining's l2: 0.000169299\tvalid_1's l2: 0.000168785\n",
      "[2115]\ttraining's l2: 0.000169186\tvalid_1's l2: 0.000168676\n",
      "[2120]\ttraining's l2: 0.00016907\tvalid_1's l2: 0.000168563\n",
      "[2125]\ttraining's l2: 0.000168886\tvalid_1's l2: 0.000168382\n",
      "[2130]\ttraining's l2: 0.000168721\tvalid_1's l2: 0.000168223\n",
      "[2135]\ttraining's l2: 0.000168582\tvalid_1's l2: 0.000168086\n",
      "[2140]\ttraining's l2: 0.000168457\tvalid_1's l2: 0.000167965\n",
      "[2145]\ttraining's l2: 0.000168307\tvalid_1's l2: 0.000167816\n",
      "[2150]\ttraining's l2: 0.00016812\tvalid_1's l2: 0.000167628\n",
      "[2155]\ttraining's l2: 0.000168006\tvalid_1's l2: 0.000167515\n",
      "[2160]\ttraining's l2: 0.000167825\tvalid_1's l2: 0.000167337\n",
      "[2165]\ttraining's l2: 0.000167618\tvalid_1's l2: 0.000167132\n",
      "[2170]\ttraining's l2: 0.000167489\tvalid_1's l2: 0.000167007\n",
      "[2175]\ttraining's l2: 0.000167348\tvalid_1's l2: 0.000166865\n",
      "[2180]\ttraining's l2: 0.000167232\tvalid_1's l2: 0.000166753\n",
      "[2185]\ttraining's l2: 0.000167091\tvalid_1's l2: 0.00016661\n",
      "[2190]\ttraining's l2: 0.000166931\tvalid_1's l2: 0.000166448\n",
      "[2195]\ttraining's l2: 0.000166774\tvalid_1's l2: 0.000166292\n",
      "[2200]\ttraining's l2: 0.000166667\tvalid_1's l2: 0.000166187\n",
      "[2205]\ttraining's l2: 0.000166524\tvalid_1's l2: 0.000166048\n",
      "[2210]\ttraining's l2: 0.000166373\tvalid_1's l2: 0.000165902\n",
      "[2215]\ttraining's l2: 0.000166208\tvalid_1's l2: 0.000165739\n",
      "[2220]\ttraining's l2: 0.00016604\tvalid_1's l2: 0.000165575\n",
      "[2225]\ttraining's l2: 0.000165898\tvalid_1's l2: 0.000165434\n",
      "[2230]\ttraining's l2: 0.000165707\tvalid_1's l2: 0.000165244\n",
      "[2235]\ttraining's l2: 0.000165546\tvalid_1's l2: 0.000165088\n",
      "[2240]\ttraining's l2: 0.000165386\tvalid_1's l2: 0.00016493\n",
      "[2245]\ttraining's l2: 0.000165289\tvalid_1's l2: 0.000164834\n",
      "[2250]\ttraining's l2: 0.000165143\tvalid_1's l2: 0.000164689\n",
      "[2255]\ttraining's l2: 0.000164982\tvalid_1's l2: 0.000164528\n",
      "[2260]\ttraining's l2: 0.00016485\tvalid_1's l2: 0.000164396\n",
      "[2265]\ttraining's l2: 0.000164719\tvalid_1's l2: 0.000164266\n",
      "[2270]\ttraining's l2: 0.000164613\tvalid_1's l2: 0.00016416\n",
      "[2275]\ttraining's l2: 0.000164509\tvalid_1's l2: 0.000164055\n",
      "[2280]\ttraining's l2: 0.000164394\tvalid_1's l2: 0.000163942\n",
      "[2285]\ttraining's l2: 0.000164275\tvalid_1's l2: 0.000163825\n",
      "[2290]\ttraining's l2: 0.000164121\tvalid_1's l2: 0.000163674\n",
      "[2295]\ttraining's l2: 0.000163975\tvalid_1's l2: 0.000163531\n",
      "[2300]\ttraining's l2: 0.00016384\tvalid_1's l2: 0.000163394\n",
      "[2305]\ttraining's l2: 0.000163673\tvalid_1's l2: 0.000163231\n",
      "[2310]\ttraining's l2: 0.000163546\tvalid_1's l2: 0.000163105\n",
      "[2315]\ttraining's l2: 0.000163411\tvalid_1's l2: 0.000162972\n",
      "[2320]\ttraining's l2: 0.000163237\tvalid_1's l2: 0.000162797\n",
      "[2325]\ttraining's l2: 0.000163104\tvalid_1's l2: 0.000162667\n",
      "[2330]\ttraining's l2: 0.000162932\tvalid_1's l2: 0.000162497\n",
      "[2335]\ttraining's l2: 0.000162828\tvalid_1's l2: 0.000162395\n",
      "[2340]\ttraining's l2: 0.0001627\tvalid_1's l2: 0.000162265\n",
      "[2345]\ttraining's l2: 0.000162597\tvalid_1's l2: 0.000162167\n",
      "[2350]\ttraining's l2: 0.000162441\tvalid_1's l2: 0.000162014\n",
      "[2355]\ttraining's l2: 0.000162285\tvalid_1's l2: 0.000161861\n",
      "[2360]\ttraining's l2: 0.000162149\tvalid_1's l2: 0.000161726\n",
      "[2365]\ttraining's l2: 0.000162018\tvalid_1's l2: 0.000161599\n",
      "[2370]\ttraining's l2: 0.000161904\tvalid_1's l2: 0.000161489\n",
      "[2375]\ttraining's l2: 0.000161757\tvalid_1's l2: 0.000161347\n",
      "[2380]\ttraining's l2: 0.000161618\tvalid_1's l2: 0.000161209\n",
      "[2385]\ttraining's l2: 0.000161459\tvalid_1's l2: 0.00016105\n",
      "[2390]\ttraining's l2: 0.000161318\tvalid_1's l2: 0.000160911\n",
      "[2395]\ttraining's l2: 0.000161143\tvalid_1's l2: 0.000160741\n",
      "[2400]\ttraining's l2: 0.000161043\tvalid_1's l2: 0.000160643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2405]\ttraining's l2: 0.000160911\tvalid_1's l2: 0.000160513\n",
      "[2410]\ttraining's l2: 0.000160787\tvalid_1's l2: 0.000160391\n",
      "[2415]\ttraining's l2: 0.000160629\tvalid_1's l2: 0.000160237\n",
      "[2420]\ttraining's l2: 0.000160473\tvalid_1's l2: 0.000160085\n",
      "[2425]\ttraining's l2: 0.00016035\tvalid_1's l2: 0.000159964\n",
      "[2430]\ttraining's l2: 0.000160248\tvalid_1's l2: 0.000159864\n",
      "[2435]\ttraining's l2: 0.000160074\tvalid_1's l2: 0.000159697\n",
      "[2440]\ttraining's l2: 0.000159938\tvalid_1's l2: 0.000159564\n",
      "[2445]\ttraining's l2: 0.0001598\tvalid_1's l2: 0.000159427\n",
      "[2450]\ttraining's l2: 0.000159649\tvalid_1's l2: 0.000159276\n",
      "[2455]\ttraining's l2: 0.000159559\tvalid_1's l2: 0.000159186\n",
      "[2460]\ttraining's l2: 0.000159421\tvalid_1's l2: 0.00015905\n",
      "[2465]\ttraining's l2: 0.000159294\tvalid_1's l2: 0.000158923\n",
      "[2470]\ttraining's l2: 0.000159168\tvalid_1's l2: 0.000158799\n",
      "[2475]\ttraining's l2: 0.000159052\tvalid_1's l2: 0.000158686\n",
      "[2480]\ttraining's l2: 0.000158947\tvalid_1's l2: 0.000158581\n",
      "[2485]\ttraining's l2: 0.000158835\tvalid_1's l2: 0.000158471\n",
      "[2490]\ttraining's l2: 0.00015874\tvalid_1's l2: 0.000158377\n",
      "[2495]\ttraining's l2: 0.000158626\tvalid_1's l2: 0.000158267\n",
      "[2500]\ttraining's l2: 0.000158475\tvalid_1's l2: 0.00015812\n",
      "[2505]\ttraining's l2: 0.000158356\tvalid_1's l2: 0.000158002\n",
      "[2510]\ttraining's l2: 0.000158177\tvalid_1's l2: 0.000157824\n",
      "[2515]\ttraining's l2: 0.000158044\tvalid_1's l2: 0.00015769\n",
      "[2520]\ttraining's l2: 0.000157926\tvalid_1's l2: 0.000157572\n",
      "[2525]\ttraining's l2: 0.000157784\tvalid_1's l2: 0.000157432\n",
      "[2530]\ttraining's l2: 0.000157688\tvalid_1's l2: 0.000157332\n",
      "[2535]\ttraining's l2: 0.000157539\tvalid_1's l2: 0.000157186\n",
      "[2540]\ttraining's l2: 0.000157422\tvalid_1's l2: 0.000157073\n",
      "[2545]\ttraining's l2: 0.000157296\tvalid_1's l2: 0.000156948\n",
      "[2550]\ttraining's l2: 0.000157187\tvalid_1's l2: 0.000156837\n",
      "[2555]\ttraining's l2: 0.000157067\tvalid_1's l2: 0.000156717\n",
      "[2560]\ttraining's l2: 0.000156919\tvalid_1's l2: 0.000156571\n",
      "[2565]\ttraining's l2: 0.000156804\tvalid_1's l2: 0.000156458\n",
      "[2570]\ttraining's l2: 0.000156679\tvalid_1's l2: 0.000156334\n",
      "[2575]\ttraining's l2: 0.000156587\tvalid_1's l2: 0.000156244\n",
      "[2580]\ttraining's l2: 0.00015646\tvalid_1's l2: 0.00015612\n",
      "[2585]\ttraining's l2: 0.000156299\tvalid_1's l2: 0.000155962\n",
      "[2590]\ttraining's l2: 0.000156192\tvalid_1's l2: 0.000155859\n",
      "[2595]\ttraining's l2: 0.000156085\tvalid_1's l2: 0.000155753\n",
      "[2600]\ttraining's l2: 0.000155986\tvalid_1's l2: 0.000155652\n",
      "[2605]\ttraining's l2: 0.000155876\tvalid_1's l2: 0.000155541\n",
      "[2610]\ttraining's l2: 0.000155718\tvalid_1's l2: 0.00015539\n",
      "[2615]\ttraining's l2: 0.000155617\tvalid_1's l2: 0.00015529\n",
      "[2620]\ttraining's l2: 0.000155491\tvalid_1's l2: 0.000155167\n",
      "[2625]\ttraining's l2: 0.000155386\tvalid_1's l2: 0.000155064\n",
      "[2630]\ttraining's l2: 0.000155299\tvalid_1's l2: 0.00015498\n",
      "[2635]\ttraining's l2: 0.000155173\tvalid_1's l2: 0.000154856\n",
      "[2640]\ttraining's l2: 0.000155089\tvalid_1's l2: 0.000154774\n",
      "[2645]\ttraining's l2: 0.000155004\tvalid_1's l2: 0.00015469\n",
      "[2650]\ttraining's l2: 0.0001549\tvalid_1's l2: 0.000154587\n",
      "[2655]\ttraining's l2: 0.000154811\tvalid_1's l2: 0.000154499\n",
      "[2660]\ttraining's l2: 0.000154696\tvalid_1's l2: 0.000154388\n",
      "[2665]\ttraining's l2: 0.000154595\tvalid_1's l2: 0.000154288\n",
      "[2670]\ttraining's l2: 0.000154472\tvalid_1's l2: 0.000154171\n",
      "[2675]\ttraining's l2: 0.000154341\tvalid_1's l2: 0.000154039\n",
      "[2680]\ttraining's l2: 0.000154224\tvalid_1's l2: 0.000153923\n",
      "[2685]\ttraining's l2: 0.00015413\tvalid_1's l2: 0.000153831\n",
      "[2690]\ttraining's l2: 0.000154022\tvalid_1's l2: 0.000153726\n",
      "[2695]\ttraining's l2: 0.000153915\tvalid_1's l2: 0.000153621\n",
      "[2700]\ttraining's l2: 0.000153801\tvalid_1's l2: 0.000153511\n",
      "[2705]\ttraining's l2: 0.000153727\tvalid_1's l2: 0.000153439\n",
      "[2710]\ttraining's l2: 0.000153653\tvalid_1's l2: 0.000153367\n",
      "[2715]\ttraining's l2: 0.000153565\tvalid_1's l2: 0.000153279\n",
      "[2720]\ttraining's l2: 0.000153431\tvalid_1's l2: 0.000153148\n",
      "[2725]\ttraining's l2: 0.000153301\tvalid_1's l2: 0.00015302\n",
      "[2730]\ttraining's l2: 0.000153189\tvalid_1's l2: 0.000152909\n",
      "[2735]\ttraining's l2: 0.000153063\tvalid_1's l2: 0.000152786\n",
      "[2740]\ttraining's l2: 0.000152969\tvalid_1's l2: 0.000152692\n",
      "[2745]\ttraining's l2: 0.000152834\tvalid_1's l2: 0.000152559\n",
      "[2750]\ttraining's l2: 0.000152737\tvalid_1's l2: 0.000152466\n",
      "[2755]\ttraining's l2: 0.000152578\tvalid_1's l2: 0.00015231\n",
      "[2760]\ttraining's l2: 0.000152453\tvalid_1's l2: 0.000152188\n",
      "[2765]\ttraining's l2: 0.000152352\tvalid_1's l2: 0.000152086\n",
      "[2770]\ttraining's l2: 0.000152242\tvalid_1's l2: 0.000151981\n",
      "[2775]\ttraining's l2: 0.000152116\tvalid_1's l2: 0.000151854\n",
      "[2780]\ttraining's l2: 0.000152018\tvalid_1's l2: 0.000151758\n",
      "[2785]\ttraining's l2: 0.0001519\tvalid_1's l2: 0.000151641\n",
      "[2790]\ttraining's l2: 0.000151765\tvalid_1's l2: 0.000151508\n",
      "[2795]\ttraining's l2: 0.000151664\tvalid_1's l2: 0.000151409\n",
      "[2800]\ttraining's l2: 0.00015156\tvalid_1's l2: 0.00015131\n",
      "[2805]\ttraining's l2: 0.000151457\tvalid_1's l2: 0.00015121\n",
      "[2810]\ttraining's l2: 0.000151357\tvalid_1's l2: 0.000151111\n",
      "[2815]\ttraining's l2: 0.000151262\tvalid_1's l2: 0.000151015\n",
      "[2820]\ttraining's l2: 0.000151143\tvalid_1's l2: 0.0001509\n",
      "[2825]\ttraining's l2: 0.00015104\tvalid_1's l2: 0.000150798\n",
      "[2830]\ttraining's l2: 0.000150907\tvalid_1's l2: 0.000150665\n",
      "[2835]\ttraining's l2: 0.000150816\tvalid_1's l2: 0.000150573\n",
      "[2840]\ttraining's l2: 0.000150711\tvalid_1's l2: 0.00015047\n",
      "[2845]\ttraining's l2: 0.00015056\tvalid_1's l2: 0.000150323\n",
      "[2850]\ttraining's l2: 0.000150458\tvalid_1's l2: 0.000150221\n",
      "[2855]\ttraining's l2: 0.00015036\tvalid_1's l2: 0.000150124\n",
      "[2860]\ttraining's l2: 0.000150279\tvalid_1's l2: 0.000150045\n",
      "[2865]\ttraining's l2: 0.000150182\tvalid_1's l2: 0.000149948\n",
      "[2870]\ttraining's l2: 0.000150069\tvalid_1's l2: 0.00014984\n",
      "[2875]\ttraining's l2: 0.000149971\tvalid_1's l2: 0.000149744\n",
      "[2880]\ttraining's l2: 0.00014988\tvalid_1's l2: 0.000149654\n",
      "[2885]\ttraining's l2: 0.000149768\tvalid_1's l2: 0.000149545\n",
      "[2890]\ttraining's l2: 0.000149657\tvalid_1's l2: 0.000149436\n",
      "[2895]\ttraining's l2: 0.000149558\tvalid_1's l2: 0.000149336\n",
      "[2900]\ttraining's l2: 0.000149448\tvalid_1's l2: 0.000149229\n",
      "[2905]\ttraining's l2: 0.000149339\tvalid_1's l2: 0.000149123\n",
      "[2910]\ttraining's l2: 0.000149235\tvalid_1's l2: 0.00014902\n",
      "[2915]\ttraining's l2: 0.000149105\tvalid_1's l2: 0.000148892\n",
      "[2920]\ttraining's l2: 0.000149001\tvalid_1's l2: 0.000148786\n",
      "[2925]\ttraining's l2: 0.00014889\tvalid_1's l2: 0.000148673\n",
      "[2930]\ttraining's l2: 0.000148811\tvalid_1's l2: 0.000148598\n",
      "[2935]\ttraining's l2: 0.000148737\tvalid_1's l2: 0.000148525\n",
      "[2940]\ttraining's l2: 0.000148634\tvalid_1's l2: 0.000148423\n",
      "[2945]\ttraining's l2: 0.000148523\tvalid_1's l2: 0.000148314\n",
      "[2950]\ttraining's l2: 0.000148413\tvalid_1's l2: 0.000148204\n",
      "[2955]\ttraining's l2: 0.000148315\tvalid_1's l2: 0.00014811\n",
      "[2960]\ttraining's l2: 0.000148235\tvalid_1's l2: 0.000148031\n",
      "[2965]\ttraining's l2: 0.000148147\tvalid_1's l2: 0.000147945\n",
      "[2970]\ttraining's l2: 0.000148034\tvalid_1's l2: 0.000147834\n",
      "[2975]\ttraining's l2: 0.000147927\tvalid_1's l2: 0.000147728\n",
      "[2980]\ttraining's l2: 0.000147833\tvalid_1's l2: 0.000147634\n",
      "[2985]\ttraining's l2: 0.000147719\tvalid_1's l2: 0.000147526\n",
      "[2990]\ttraining's l2: 0.000147644\tvalid_1's l2: 0.000147452\n",
      "[2995]\ttraining's l2: 0.000147533\tvalid_1's l2: 0.000147341\n",
      "[3000]\ttraining's l2: 0.000147431\tvalid_1's l2: 0.000147243\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l2: 0.000147431\tvalid_1's l2: 0.000147243\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import plotly.offline as py\n",
    "# py.init_notebook_mode(connected=True)\n",
    "# import plotly.graph_objs as go\n",
    "# import plotly.tools as tls\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"baseline_logfile_1_15\",\n",
    "                    filemode=\"a+\", format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "\n",
    "\n",
    "train = pd.read_csv('jinnan_round1_train_20181227.csv', encoding = 'gb18030')\n",
    "test  = pd.read_csv('jinnan_round1_testA_20181227.csv', encoding = 'gb18030')\n",
    "\n",
    "target_col = \"收率\"\n",
    "\n",
    "# 删除异常值\n",
    "print(train[train['收率'] < 0.87])\n",
    "\n",
    "train = train[train['收率'] > 0.87]\n",
    "train.loc[train['B14'] == 40, 'B14'] = 400\n",
    "train = train[train['B14']>=400]\n",
    "\n",
    "# 合并数据集, 顺便处理异常数据\n",
    "target = train['收率']\n",
    "train.loc[train['A25'] == '1900/3/10 0:00', 'A25'] = train['A25'].value_counts().values[0]\n",
    "train['A25'] = train['A25'].astype(int)\n",
    "train.loc[train['B14'] == 40, 'B14'] = 400\n",
    "# test.loc[test['B14'] == 385, 'B14'] = 385\n",
    "\n",
    "test_select = {}\n",
    "for v in [280, 385, 390, 785]:\n",
    "    print(v)\n",
    "    print(test[test['B14'] == v]['样本id'])\n",
    "    test_select[v] = test[test['B14'] == v]['样本id'].index\n",
    "    print(test[test['B14'] == v]['样本id'].index)\n",
    "    print(test_select[v])\n",
    "\n",
    "del train['收率']\n",
    "data = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "data = data.fillna(-1)\n",
    "\n",
    "def timeTranSecond(t):\n",
    "    try:\n",
    "        t, m, s = t.split(\":\")\n",
    "    except:\n",
    "        if t == '1900/1/9 7:00':\n",
    "            return 7 * 3600 / 3600\n",
    "        elif t == '1900/1/1 2:30':\n",
    "            return (2 * 3600 + 30 * 60) / 3600\n",
    "        elif t == -1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    try:\n",
    "        tm = (int(t) * 3600 + int(m) * 60 + int(s)) / 3600\n",
    "    except:\n",
    "        return (30 * 60) / 3600\n",
    "\n",
    "    return tm\n",
    "\n",
    "\n",
    "for f in ['A5', 'A7', 'A9', 'A11', 'A14', 'A16', 'A24', 'A26', 'B5', 'B7']:\n",
    "    try:\n",
    "        data[f] = data[f].apply(timeTranSecond)\n",
    "    except:\n",
    "        print(f, '应该在前面被删除了！')\n",
    "\n",
    "\n",
    "def getDuration(se):\n",
    "    try:\n",
    "        sh, sm, eh, em = re.findall(r\"\\d+\\.?\\d*\", se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1\n",
    "\n",
    "    try:\n",
    "        if int(sh) > int(eh):\n",
    "            tm = (int(eh) * 3600 + int(em) * 60 - int(sm) * 60 - int(sh) * 3600) / 3600 + 24\n",
    "        else:\n",
    "            tm = (int(eh) * 3600 + int(em) * 60 - int(sm) * 60 - int(sh) * 3600) / 3600\n",
    "    except:\n",
    "        if se == '19:-20:05':\n",
    "            return 1\n",
    "        elif se == '15:00-1600':\n",
    "            return 1\n",
    "\n",
    "    return tm\n",
    "\n",
    "\n",
    "for f in ['A20', 'A28', 'B4', 'B9', 'B10', 'B11']:\n",
    "    data[f] = data.apply(lambda df: getDuration(df[f]), axis=1)\n",
    "\n",
    "data['样本id'] = data['样本id'].apply(lambda x: x.split('_')[1])\n",
    "data['样本id'] = data['样本id'].astype(int)\n",
    "\n",
    "# 基本数据处理完毕, 开始拼接数据\n",
    "train = data[:train.shape[0]]\n",
    "test  = data[train.shape[0]:]\n",
    "\n",
    "train['target'] = list(target)\n",
    "\n",
    "new_train = train.copy()\n",
    "new_train = new_train.sort_values(['样本id'], ascending=True)\n",
    "train_copy = train.copy()\n",
    "train_copy = train_copy.sort_values(['样本id'], ascending=True)\n",
    "\n",
    "# 把train加长两倍\n",
    "train_len = len(new_train)\n",
    "new_train = pd.concat([new_train, train_copy])\n",
    "\n",
    "# 把加长两倍的train拼接到test后面\n",
    "new_test = test.copy()\n",
    "new_test = pd.concat([new_test, new_train])\n",
    "\n",
    "import sys\n",
    "# 开始向后做差\n",
    "diff_train = pd.DataFrame()\n",
    "ids = list(train_copy['样本id'].values)\n",
    "print(ids)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# 构造新的训练集\n",
    "if os.path.exists('diff_train.csv'):\n",
    "    diff_train = pd.read_csv('diff_train.csv')\n",
    "else:\n",
    "    for i in tqdm(range(1, train_len)):\n",
    "        # 分别间隔 -1, -2, ... -len行 进行差值,得到实验的所有对比实验\n",
    "        diff_tmp = new_train.diff(-i)\n",
    "        diff_tmp = diff_tmp[:train_len]\n",
    "        diff_tmp.columns = [col_ + '_difference' for col_ in\n",
    "                            diff_tmp.columns.values]\n",
    "        # 求完差值后加上样本id\n",
    "        diff_tmp['样本id'] = ids\n",
    "        diff_train = pd.concat([diff_train, diff_tmp])\n",
    "\n",
    "    # diff_train.to_csv('../input/diff_train.csv', index=False)\n",
    "\n",
    "# 构造新的测试集\n",
    "diff_test = pd.DataFrame()\n",
    "ids_test = list(test['样本id'].values)\n",
    "test_len = len(test)\n",
    "\n",
    "\n",
    "if os.path.exists('diff_test.csv'):\n",
    "    diff_test = pd.read_csv('diff_test.csv')\n",
    "else:\n",
    "    for i in tqdm(range(test_len, test_len+train_len)):\n",
    "        # 分别间隔 - test_len , -test_len -1 ,.... - test_len - train_len +1 进行差值, 得到实验的所有对比实验\n",
    "        diff_tmp = new_test.diff(-i)\n",
    "        diff_tmp = diff_tmp[:test_len]\n",
    "        diff_tmp.columns = [col_ + '_difference' for col_ in\n",
    "                            diff_tmp.columns.values]\n",
    "        # 求完差值后加上样本id\n",
    "        diff_tmp['样本id'] = ids_test\n",
    "        diff_test = pd.concat([diff_test, diff_tmp])\n",
    "\n",
    "    diff_test = diff_test[diff_train.columns]\n",
    "    # diff_test.to_csv('../input/diff_test.csv', index=False)\n",
    "\n",
    "\n",
    "print(train.columns.values)\n",
    "# 和train顺序一致的target\n",
    "train_target = train['target']\n",
    "train.drop(['target'], axis=1, inplace=True)\n",
    "# 拼接原始特征\n",
    "diff_train = pd.merge(diff_train, train, how='left', on='样本id')\n",
    "diff_test = pd.merge(diff_test, test, how='left', on='样本id')\n",
    "\n",
    "target = diff_train['target_difference']\n",
    "diff_train.drop(['target_difference'], axis=1, inplace=True)\n",
    "diff_test.drop(['target_difference'], axis=1, inplace=True)\n",
    "\n",
    "X_train = diff_train\n",
    "y_train = target\n",
    "X_test = diff_test\n",
    "\n",
    "print(X_train.columns.values)\n",
    "\n",
    "param = {'num_leaves': 31, #31\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         # \"min_child_samples\": 30,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l2\": 0.1,\n",
    "         # \"lambda_l1\": 0.1,\n",
    "         'num_thread': 4,\n",
    "         \"verbosity\": -1}\n",
    "groups = X_train['样本id'].values\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_lgb = np.zeros(len(diff_train))\n",
    "predictions_lgb = np.zeros(len(diff_test))\n",
    "\n",
    "feature_importance = pd.DataFrame()\n",
    "feature_importance['feature_name'] = X_train.columns.values\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    dev = X_train.iloc[trn_idx]\n",
    "    val = X_train.iloc[val_idx]\n",
    "\n",
    "    trn_data = lgb.Dataset(dev, y_train.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(val, y_train.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=5,\n",
    "                    early_stopping_rounds=100)\n",
    "    oof_lgb[val_idx] = clf.predict(val, num_iteration=clf.best_iteration)\n",
    "\n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    importance = clf.feature_importance(importance_type='gain')\n",
    "    feature_name = clf.feature_name()\n",
    "    tmp_df = pd.DataFrame({'feature_name':feature_name, 'importance':importance})\n",
    "\n",
    "    feature_importance = pd.merge(feature_importance, tmp_df, how='left',\n",
    "                                  on='feature_name')\n",
    "    print(len(feature_importance['feature_name']))\n",
    "\n",
    "print(len(diff_train))\n",
    "feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "# 还原train target\n",
    "diff_train['compare_id'] = diff_train['样本id'] - diff_train['样本id_difference']\n",
    "train['compare_id'] = train['样本id']\n",
    "train['compare_target'] = list(train_target)\n",
    "# 把做差的target拼接回去\n",
    "diff_train = pd.merge(diff_train, train[['compare_id', 'compare_target']], how='left', on='compare_id')\n",
    "print(diff_train.columns.values)\n",
    "diff_train['pre_target_diff'] = oof_lgb\n",
    "diff_train['pre_target'] = diff_train['pre_target_diff'] + diff_train['compare_target']\n",
    "\n",
    "mean_result = diff_train.groupby('样本id')['pre_target'].mean().reset_index(name='pre_target_mean')\n",
    "true_result = train[['样本id', 'compare_target']]\n",
    "mean_result = pd.merge(mean_result, true_result, how='left', on='样本id')\n",
    "print(mean_result)\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, target)))\n",
    "logging.info(\"Lgb CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, target)))\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(mean_result['pre_target_mean'].values,  mean_result['compare_target'].values)))\n",
    "logging.info(\"Lgb CV score: {:<8.8f}\".format(mean_squared_error(mean_result['pre_target_mean'].values,  mean_result['compare_target'].values)))\n",
    "\n",
    "# pre_target = mean_result['pre_target_mean'].values\n",
    "# true_target = mean_result['']\n",
    "\n",
    "# 还原test target\n",
    "diff_test['compare_id'] = diff_test['样本id'] - diff_test['样本id_difference']\n",
    "diff_test = pd.merge(diff_test, train[['compare_id', 'compare_target']], how='left', on='compare_id')\n",
    "diff_test['pre_target_diff'] = predictions_lgb\n",
    "diff_test['pre_target'] = diff_test['pre_target_diff'] + diff_test['compare_target']\n",
    "\n",
    "mean_result_test = diff_test.groupby(diff_test['样本id'], sort=False)['pre_target'].mean().reset_index(name='pre_target_mean')\n",
    "print(mean_result_test)\n",
    "test = pd.merge(test, mean_result_test, how='left', on='样本id')\n",
    "sub_df = pd.read_csv('jinnan_round1_submit_20181227.csv', header=None)\n",
    "sub_df[1] = test['pre_target_mean']\n",
    "sub_df[1] = sub_df[1].apply(lambda x:round(x, 3))\n",
    "\n",
    "for v in test_select.keys():\n",
    "    if v == 280:\n",
    "        x = 0.947\n",
    "    elif v == 385 or v == 785:\n",
    "        x = 0.879\n",
    "    elif v == 390:\n",
    "        x = 0.89\n",
    "\n",
    "    print(v)\n",
    "    print(test_select[v])\n",
    "    # sub_df.iloc[test_select[v]][1] = x\n",
    "    sub_df.loc[test_select[v], 1] = x\n",
    "\n",
    "sub_df.to_csv('jinnan_round_submit_diff.csv', index=False, header=False)\n",
    "\n",
    "print(len(diff_train))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
