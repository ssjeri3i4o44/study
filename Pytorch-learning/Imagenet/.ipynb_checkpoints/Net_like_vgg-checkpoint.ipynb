{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:562: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "#define hyper-parameters\n",
    "num_classes = 10\n",
    "num_epoch = 1\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#define transform\n",
    "transforms = torchvision.transforms.Compose([torchvision.transforms.RandomSizedCrop(28),\n",
    "                                             torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                            torchvision.transforms.ToTensor()])\n",
    "\n",
    "#download dataset\n",
    "train_dataset = torchvision.datasets.MNIST(download=True,root='E:\\\\code\\\\pytorch\\\\data\\\\MNIST',\n",
    "                                                  train=True,transform=transforms)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(download=True,root='E:\\\\code\\\\pytorch\\\\data\\\\MNIST',\n",
    "                                                train=False, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "#dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,shuffle=True,\n",
    "                                           num_workers=6,batch_size=batch_size)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,shuffle=False,\n",
    "                                          num_workers=6,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11(torch.nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(VGG11,self).__init__()\n",
    "        self.feature = torch.nn.Sequential(torch.nn.Conv2d(1,64,kernel_size=3,bias=True,stride=1,padding=1),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                          torch.nn.Conv2d(64,128,kernel_size=3,bias=True,stride=1,padding=1),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                          torch.nn.Conv2d(128,256,kernel_size=3,bias=True,stride=1,padding=1),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.Conv2d(256,256,kernel_size=3,bias=True,stride=1,padding=1),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                                          torch.nn.Conv2d(256,512,kernel_size=3,bias=True,stride=1,padding=1),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.Conv2d(512,512,kernel_size=3,bias=True,stride=1,padding=1),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "        self.classification = torch.nn.Sequential(torch.nn.Linear(512,num_classes),\n",
    "                                                 torch.nn.Softmax())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.feature(x)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.classification(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], step: [100/600], loss: [2.1495]\n",
      "Epoch: [1/1], step: [200/600], loss: [2.0896]\n",
      "Epoch: [1/1], step: [300/600], loss: [1.9846]\n",
      "Epoch: [1/1], step: [400/600], loss: [1.9329]\n",
      "Epoch: [1/1], step: [500/600], loss: [1.8367]\n",
      "Epoch: [1/1], step: [600/600], loss: [1.7953]\n",
      "Test accuracy of the model is 84.26%\n"
     ]
    }
   ],
   "source": [
    "model = VGG11().to(device)\n",
    "\n",
    "#define loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "#train model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1)%100 == 0:\n",
    "            print('Epoch: [{}/{}], step: [{}/{}], loss: [{:.4f}]'.format(epoch+1,num_epoch,i+1,total_step,loss.item()))\n",
    "\n",
    "#define test model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images,labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test accuracy of the model is {}%'.format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建VGG结构网络\n",
    "\n",
    "VGG结构网络是最常见的网络结构之一，相对于Alexnet网络来说，VGG将7\\*7的卷积核大小都转化成3\\*3的卷积核，这样的做法相对来说减少了在卷积过程中，图像的信息丢失，而且减少的卷积层的参数，同时，网络结构的层数也加深了，最多可以达到19层，并且没有出现网络退化的效果。\n",
    "\n",
    "VGG的缺点也很明显，就是全连接层的参数太多，网络的大部分参数都集中在全连接层中，这也导致了VGG所需要的计算资源比较巨大。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
