{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define\n",
    "num_classes = 1000\n",
    "\n",
    "class myvgg(nn.Module):\n",
    "    def __init__(self,model):\n",
    "        super(myvgg,self).__init__()\n",
    "        self.vgg11 = nn.Sequential(*list(model.features.children())[:-5])\n",
    "        self.transconv1 = nn.ConvTranspose2d(in_channels=256,out_channels=256,bias=True,kernel_size=3,stride=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.transconv2 = nn.ConvTranspose2d(in_channels=256,out_channels=512,bias=True,kernel_size=3,stride=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.unpool = nn.MaxUnpool2d(kernel_size=3,stride=2,padding=2)\n",
    "        self.fc = nn.Linear(11*11*128,num_classes)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    #define forward\n",
    "    def forward(self,x):\n",
    "        out = self.vgg11(x)\n",
    "        out = self.transconv1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.transconv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.unpool(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg11 = torchvision.models.vgg11(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myvgg(\n",
       "  (vgg11): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (transconv1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (relu1): ReLU()\n",
       "  (transconv2): ConvTranspose2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (relu2): ReLU()\n",
       "  (unpool): MaxUnpool2d(kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
       "  (fc): Linear(in_features=15488, out_features=1000, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg = myvgg(vgg11)\n",
    "vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改torchvision.models的网络结构\n",
    "\n",
    "前面联系编写了类似于VGG结构的网络模型，当我们想要训练自己的数据集或者想要修改模型的网络层时，就需要通过原始的模型进行修改，我们可以使用children函数进行原始模型的网络层切分，例子：\n",
    "\n",
    "***\n",
    "nn.Sequential(*list(model.children())[:-5])\n",
    "***\n",
    "\n",
    "要注意的是，我们只能获得每个Sequential中切分网络，所以当你需要接下来的网络的时候，你就需要再获取下一个Sequential，然后切分，最后拼接一下，\n",
    "在自己添加网络层的时候，要小心通道数的匹配，还有最后全连接层的节点匹配，如果不知道怎么计算每层的特征图大小，就不知道最后全连接层需要输入\n",
    "多少大小的矩阵，计算的公式在Pytorch的官方文档中有，感觉Pytorch的文档还是很好的，当初应该早点用Pytorch的。。。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
